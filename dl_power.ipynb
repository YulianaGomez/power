{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import nbimporter\n",
    "import power_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Developing a Baseline Neural Network Model\n",
    "Creating a baseline model for the regression problem using the Scikit-learn wrapper by the Keras library\n",
    "\n",
    "source: https://machinelearningmastery.com/regression-tutorial-keras-deep-learning-library-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  cores    freq      Rate     Power      Energy  WU_PWR_AVG  WU_ENERGY\n",
      "0  0xe6  100000  5.887958  5.439624  461.927430         NaN        NaN\n",
      "1  0xe6  200000  5.888939  5.474008  464.770101         NaN        NaN\n",
      "2  0xe6  400000  5.897709  5.441137  461.291977         NaN        NaN\n",
      "3  0xe6  600000  5.897312  5.442045  461.399975         NaN        NaN\n",
      "4  0xe6  700000  5.908167  5.432657  459.758156         NaN        NaN\n"
     ]
    }
   ],
   "source": [
    "#Import Data\n",
    "#file_path = '/Users/yzamora/power/STREAM_big.results'\n",
    "file_path = '/Users/yzamora/power/all.out'\n",
    "df = pd.read_csv(file_path, sep='\\s+')\n",
    "print (df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    cores     freq      Rate     Power      Energy  WU_PWR_AVG  WU_ENERGY  \\\n",
      "0    0xe6   100000  5.887958  5.439624  461.927430         NaN        NaN   \n",
      "1    0xe6   200000  5.888939  5.474008  464.770101         NaN        NaN   \n",
      "2    0xe6   400000  5.897709  5.441137  461.291977         NaN        NaN   \n",
      "3    0xe6   600000  5.897312  5.442045  461.399975         NaN        NaN   \n",
      "4    0xe6   700000  5.908167  5.432657  459.758156         NaN        NaN   \n",
      "5    0xe6   800000  5.893648  5.440728  461.575041         NaN        NaN   \n",
      "6    0xe6  1000000  5.892087  5.463399  463.621307         NaN        NaN   \n",
      "7    0xe6  1200000  5.879515  5.468053  465.008695         NaN        NaN   \n",
      "8    0xe6  1400000  5.890988  5.457655  463.220651         NaN        NaN   \n",
      "9    0xda   100000  5.904099  5.387178  456.223404         NaN        NaN   \n",
      "10   0xda   200000  5.900255  5.434772  460.553992         NaN        NaN   \n",
      "11   0xda   400000  5.891115  5.452016  462.731679         NaN        NaN   \n",
      "12   0xda   600000  5.890124  5.460129  463.498338         NaN        NaN   \n",
      "13   0xda   700000  5.886829  5.464754  464.150520         NaN        NaN   \n",
      "14   0xda   800000  5.889059  5.475984  464.928564         NaN        NaN   \n",
      "15   0xda  1000000  5.897247  5.458857  462.830828         NaN        NaN   \n",
      "16   0xda  1200000  5.874792  5.485718  466.885618         NaN        NaN   \n",
      "17   0xda  1400000  5.889206  5.465076  463.990417         NaN        NaN   \n",
      "18   0x2d   100000  5.217183  3.554354  340.638979         NaN        NaN   \n",
      "19   0x2d   200000  5.214908  3.516393  337.147892         NaN        NaN   \n",
      "20   0x2d   400000  5.218577  3.497162  335.068336         NaN        NaN   \n",
      "21   0x2d   600000  5.221351  3.504558  335.598576         NaN        NaN   \n",
      "22   0x2d   700000  5.217522  3.504021  335.793486         NaN        NaN   \n",
      "23   0x2d   800000  5.223293  3.503279  335.351382         NaN        NaN   \n",
      "24   0x2d  1000000  5.220663  3.503156  335.508460         NaN        NaN   \n",
      "25   0x2d  1200000  5.222721  3.507025  335.746791         NaN        NaN   \n",
      "26   0x2d  1400000  5.220195  3.505391  335.752659         NaN        NaN   \n",
      "27   0x7e   100000  5.865554  5.631357  480.036017         NaN        NaN   \n",
      "28   0x7e   200000  5.849438  5.722359  489.136947         NaN        NaN   \n",
      "29   0x7e   400000  5.854089  5.751586  491.244685         NaN        NaN   \n",
      "..    ...      ...       ...       ...         ...         ...        ...   \n",
      "851  0x4e  1000000  5.250843  3.444827  328.026072         NaN        NaN   \n",
      "852  0x4e  1200000  5.245897  3.452810  329.095953         NaN        NaN   \n",
      "853  0x4e  1400000  5.247637  3.443291  328.079865         NaN        NaN   \n",
      "854  0xa9   100000  6.159271  4.526939  367.489664         NaN        NaN   \n",
      "855  0xa9   200000  6.156690  4.586772  372.502762         NaN        NaN   \n",
      "856  0xa9   400000  6.157651  4.583316  372.163884         NaN        NaN   \n",
      "857  0xa9   600000  6.155979  4.593227  373.070164         NaN        NaN   \n",
      "858  0xa9   700000  6.156774  4.582739  372.170191         NaN        NaN   \n",
      "859  0xa9   800000  6.154952  4.593637  373.165939         NaN        NaN   \n",
      "860  0xa9  1000000  6.157669  4.586491  372.420775         NaN        NaN   \n",
      "861  0xa9  1200000  6.158964  4.570123  371.013553         NaN        NaN   \n",
      "862  0xa9  1400000  6.155409  4.596238  373.349195         NaN        NaN   \n",
      "863  0x1e   100000  5.254973  3.487709  331.848187         NaN        NaN   \n",
      "864  0x1e   200000  5.254573  3.471489  330.330230         NaN        NaN   \n",
      "865  0x1e   400000  5.253329  3.466142  329.899423         NaN        NaN   \n",
      "866  0x1e   600000  5.251251  3.476953  331.059470         NaN        NaN   \n",
      "867  0x1e   700000  5.254311  3.472912  330.481958         NaN        NaN   \n",
      "868  0x1e   800000  5.254340  3.473696  330.554827         NaN        NaN   \n",
      "869  0x1e  1000000  5.253418  3.471254  330.380417         NaN        NaN   \n",
      "870  0x1e  1200000  5.253360  3.470936  330.353622         NaN        NaN   \n",
      "871  0x1e  1400000  5.251410  3.477935  331.142886         NaN        NaN   \n",
      "872  0xd3   100000  5.891107  5.298956  449.741471         NaN        NaN   \n",
      "873  0xd3   200000  5.893966  5.382740  456.631291         NaN        NaN   \n",
      "874  0xd3   400000  5.903506  5.400578  457.404113         NaN        NaN   \n",
      "875  0xd3   600000  5.893485  5.417686  459.633229         NaN        NaN   \n",
      "876  0xd3   700000  5.893981  5.411821  459.097222         NaN        NaN   \n",
      "877  0xd3   800000  5.895936  5.421249  459.744142         NaN        NaN   \n",
      "878  0xd3  1000000  5.896034  5.427183  460.239771         NaN        NaN   \n",
      "879  0xd3  1200000  5.895737  5.430571  460.550434         NaN        NaN   \n",
      "880  0xd3  1400000  5.894369  5.441322  461.569388         NaN        NaN   \n",
      "\n",
      "     big_cores  lil_cores  total_cores  core-0  core-1  core-2  core-3  \\\n",
      "0            3          2            5       1       1       1       0   \n",
      "1            3          2            5       1       1       1       0   \n",
      "2            3          2            5       1       1       1       0   \n",
      "3            3          2            5       1       1       1       0   \n",
      "4            3          2            5       1       1       1       0   \n",
      "5            3          2            5       1       1       1       0   \n",
      "6            3          2            5       1       1       1       0   \n",
      "7            3          2            5       1       1       1       0   \n",
      "8            3          2            5       1       1       1       0   \n",
      "9            3          2            5       1       1       0       1   \n",
      "10           3          2            5       1       1       0       1   \n",
      "11           3          2            5       1       1       0       1   \n",
      "12           3          2            5       1       1       0       1   \n",
      "13           3          2            5       1       1       0       1   \n",
      "14           3          2            5       1       1       0       1   \n",
      "15           3          2            5       1       1       0       1   \n",
      "16           3          2            5       1       1       0       1   \n",
      "17           3          2            5       1       1       0       1   \n",
      "18           1          3            4       0       0       1       0   \n",
      "19           1          3            4       0       0       1       0   \n",
      "20           1          3            4       0       0       1       0   \n",
      "21           1          3            4       0       0       1       0   \n",
      "22           1          3            4       0       0       1       0   \n",
      "23           1          3            4       0       0       1       0   \n",
      "24           1          3            4       0       0       1       0   \n",
      "25           1          3            4       0       0       1       0   \n",
      "26           1          3            4       0       0       1       0   \n",
      "27           3          3            6       0       1       1       1   \n",
      "28           3          3            6       0       1       1       1   \n",
      "29           3          3            6       0       1       1       1   \n",
      "..         ...        ...          ...     ...     ...     ...     ...   \n",
      "851          1          3            4       0       1       0       0   \n",
      "852          1          3            4       0       1       0       0   \n",
      "853          1          3            4       0       1       0       0   \n",
      "854          2          2            4       1       0       1       0   \n",
      "855          2          2            4       1       0       1       0   \n",
      "856          2          2            4       1       0       1       0   \n",
      "857          2          2            4       1       0       1       0   \n",
      "858          2          2            4       1       0       1       0   \n",
      "859          2          2            4       1       0       1       0   \n",
      "860          2          2            4       1       0       1       0   \n",
      "861          2          2            4       1       0       1       0   \n",
      "862          2          2            4       1       0       1       0   \n",
      "863          1          3            4       0       0       0       1   \n",
      "864          1          3            4       0       0       0       1   \n",
      "865          1          3            4       0       0       0       1   \n",
      "866          1          3            4       0       0       0       1   \n",
      "867          1          3            4       0       0       0       1   \n",
      "868          1          3            4       0       0       0       1   \n",
      "869          1          3            4       0       0       0       1   \n",
      "870          1          3            4       0       0       0       1   \n",
      "871          1          3            4       0       0       0       1   \n",
      "872          3          2            5       1       1       0       1   \n",
      "873          3          2            5       1       1       0       1   \n",
      "874          3          2            5       1       1       0       1   \n",
      "875          3          2            5       1       1       0       1   \n",
      "876          3          2            5       1       1       0       1   \n",
      "877          3          2            5       1       1       0       1   \n",
      "878          3          2            5       1       1       0       1   \n",
      "879          3          2            5       1       1       0       1   \n",
      "880          3          2            5       1       1       0       1   \n",
      "\n",
      "     core-4  core-5  core-6  core-7  \n",
      "0         0       1       1       0  \n",
      "1         0       1       1       0  \n",
      "2         0       1       1       0  \n",
      "3         0       1       1       0  \n",
      "4         0       1       1       0  \n",
      "5         0       1       1       0  \n",
      "6         0       1       1       0  \n",
      "7         0       1       1       0  \n",
      "8         0       1       1       0  \n",
      "9         1       0       1       0  \n",
      "10        1       0       1       0  \n",
      "11        1       0       1       0  \n",
      "12        1       0       1       0  \n",
      "13        1       0       1       0  \n",
      "14        1       0       1       0  \n",
      "15        1       0       1       0  \n",
      "16        1       0       1       0  \n",
      "17        1       0       1       0  \n",
      "18        1       1       0       1  \n",
      "19        1       1       0       1  \n",
      "20        1       1       0       1  \n",
      "21        1       1       0       1  \n",
      "22        1       1       0       1  \n",
      "23        1       1       0       1  \n",
      "24        1       1       0       1  \n",
      "25        1       1       0       1  \n",
      "26        1       1       0       1  \n",
      "27        1       1       1       0  \n",
      "28        1       1       1       0  \n",
      "29        1       1       1       0  \n",
      "..      ...     ...     ...     ...  \n",
      "851       1       1       1       0  \n",
      "852       1       1       1       0  \n",
      "853       1       1       1       0  \n",
      "854       1       0       0       1  \n",
      "855       1       0       0       1  \n",
      "856       1       0       0       1  \n",
      "857       1       0       0       1  \n",
      "858       1       0       0       1  \n",
      "859       1       0       0       1  \n",
      "860       1       0       0       1  \n",
      "861       1       0       0       1  \n",
      "862       1       0       0       1  \n",
      "863       1       1       1       0  \n",
      "864       1       1       1       0  \n",
      "865       1       1       1       0  \n",
      "866       1       1       1       0  \n",
      "867       1       1       1       0  \n",
      "868       1       1       1       0  \n",
      "869       1       1       1       0  \n",
      "870       1       1       1       0  \n",
      "871       1       1       1       0  \n",
      "872       0       0       1       1  \n",
      "873       0       0       1       1  \n",
      "874       0       0       1       1  \n",
      "875       0       0       1       1  \n",
      "876       0       0       1       1  \n",
      "877       0       0       1       1  \n",
      "878       0       0       1       1  \n",
      "879       0       0       1       1  \n",
      "880       0       0       1       1  \n",
      "\n",
      "[881 rows x 18 columns]\n"
     ]
    }
   ],
   "source": [
    "df = power_analysis.create_col(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['cores','WU_PWR_AVG','WU_ENERGY','big_cores','lil_cores','total_cores'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     freq      Rate     Power      Energy  core-0  core-1  core-2  core-3  \\\n",
      "0  100000  5.887958  5.439624  461.927430       1       1       1       0   \n",
      "1  200000  5.888939  5.474008  464.770101       1       1       1       0   \n",
      "2  400000  5.897709  5.441137  461.291977       1       1       1       0   \n",
      "3  600000  5.897312  5.442045  461.399975       1       1       1       0   \n",
      "4  700000  5.908167  5.432657  459.758156       1       1       1       0   \n",
      "\n",
      "   core-4  core-5  core-6  core-7  \n",
      "0       0       1       1       0  \n",
      "1       0       1       1       0  \n",
      "2       0       1       1       0  \n",
      "3       0       1       1       0  \n",
      "4       0       1       1       0  \n",
      "X size: (881, 9)\n",
      "y size (881,)\n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n",
    "X = df[['freq','core-0','core-1','core-2','core-3','core-4','core-5','core-6','core-7']]\n",
    "y = df['Power']\n",
    "\n",
    "print (\"X size:\", X.shape)\n",
    "print (\"y size\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define base model\n",
    "def baseline_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(9, input_dim=9, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "# evaluate model with standardized dataset\n",
    "estimator = KerasRegressor(build_fn=baseline_model, epochs=100, batch_size=5, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -22.69 (39.45) MSE\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(estimator, X, y, cv=kfold)\n",
    "print(\"Results: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning Network Topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "def larger_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(9, input_dim=9, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(6, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Larger: -0.04 (0.01) MSE\n",
      "Variance: 0.00 \n"
     ]
    }
   ],
   "source": [
    "numpy.random.seed(seed)\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=larger_model, epochs=50, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, y, cv=kfold)\n",
    "print(\"Larger: %.2f (%.2f) MSE\" % (results.mean(), results.std()))\n",
    "print(\"Variance: %.2f \" % (results.var()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wider Network Topology\n",
    "Increasing the representational capability of the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define wider model\n",
    "def wider_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_dim=9, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wider: -0.07 (0.04) MSE\n"
     ]
    }
   ],
   "source": [
    "numpy.random.seed(seed)\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=wider_model, epochs=100, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, y, cv=kfold)\n",
    "print(\"Wider: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating deep learning models \n",
    "Creating simple multi-layer neural network, 10-fold stratified cross-validation, using grid search to evaluate different configurations for nn model and report on the combination that provides the best-estimated performance:\n",
    "\n",
    "source: https://machinelearningmastery.com/use-keras-deep-learning-models-scikit-learn-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    cores     freq      Rate     Power      Energy  WU_PWR_AVG  WU_ENERGY  \\\n",
      "0    0xe6   100000  5.887958  5.439624  461.927430         NaN        NaN   \n",
      "1    0xe6   200000  5.888939  5.474008  464.770101         NaN        NaN   \n",
      "2    0xe6   400000  5.897709  5.441137  461.291977         NaN        NaN   \n",
      "3    0xe6   600000  5.897312  5.442045  461.399975         NaN        NaN   \n",
      "4    0xe6   700000  5.908167  5.432657  459.758156         NaN        NaN   \n",
      "5    0xe6   800000  5.893648  5.440728  461.575041         NaN        NaN   \n",
      "6    0xe6  1000000  5.892087  5.463399  463.621307         NaN        NaN   \n",
      "7    0xe6  1200000  5.879515  5.468053  465.008695         NaN        NaN   \n",
      "8    0xe6  1400000  5.890988  5.457655  463.220651         NaN        NaN   \n",
      "9    0xda   100000  5.904099  5.387178  456.223404         NaN        NaN   \n",
      "10   0xda   200000  5.900255  5.434772  460.553992         NaN        NaN   \n",
      "11   0xda   400000  5.891115  5.452016  462.731679         NaN        NaN   \n",
      "12   0xda   600000  5.890124  5.460129  463.498338         NaN        NaN   \n",
      "13   0xda   700000  5.886829  5.464754  464.150520         NaN        NaN   \n",
      "14   0xda   800000  5.889059  5.475984  464.928564         NaN        NaN   \n",
      "15   0xda  1000000  5.897247  5.458857  462.830828         NaN        NaN   \n",
      "16   0xda  1200000  5.874792  5.485718  466.885618         NaN        NaN   \n",
      "17   0xda  1400000  5.889206  5.465076  463.990417         NaN        NaN   \n",
      "18   0x2d   100000  5.217183  3.554354  340.638979         NaN        NaN   \n",
      "19   0x2d   200000  5.214908  3.516393  337.147892         NaN        NaN   \n",
      "20   0x2d   400000  5.218577  3.497162  335.068336         NaN        NaN   \n",
      "21   0x2d   600000  5.221351  3.504558  335.598576         NaN        NaN   \n",
      "22   0x2d   700000  5.217522  3.504021  335.793486         NaN        NaN   \n",
      "23   0x2d   800000  5.223293  3.503279  335.351382         NaN        NaN   \n",
      "24   0x2d  1000000  5.220663  3.503156  335.508460         NaN        NaN   \n",
      "25   0x2d  1200000  5.222721  3.507025  335.746791         NaN        NaN   \n",
      "26   0x2d  1400000  5.220195  3.505391  335.752659         NaN        NaN   \n",
      "27   0x7e   100000  5.865554  5.631357  480.036017         NaN        NaN   \n",
      "28   0x7e   200000  5.849438  5.722359  489.136947         NaN        NaN   \n",
      "29   0x7e   400000  5.854089  5.751586  491.244685         NaN        NaN   \n",
      "..    ...      ...       ...       ...         ...         ...        ...   \n",
      "556  0x6b   100000  6.079709  4.623613  380.249169         NaN        NaN   \n",
      "557  0x6b   200000  6.082629  4.585490  376.932780         NaN        NaN   \n",
      "558  0x6b   400000  6.083342  4.570231  375.634598         NaN        NaN   \n",
      "559  0x6b   600000  6.078204  4.582674  376.975804         NaN        NaN   \n",
      "560  0x6b   700000  6.082823  4.573280  375.917213         NaN        NaN   \n",
      "561  0x6b   800000  6.077764  4.576958  376.532603         NaN        NaN   \n",
      "562  0x6b  1000000  6.084003  4.570978  375.655313         NaN        NaN   \n",
      "563  0x6b  1200000  6.086356  4.570246  375.449822         NaN        NaN   \n",
      "564  0x6b  1400000  6.083299  4.567618  375.422572         NaN        NaN   \n",
      "565  0x5b   100000  6.087015  4.564581  374.943812         NaN        NaN   \n",
      "566  0x5b   200000  6.084492  4.570182  375.559733         NaN        NaN   \n",
      "567  0x5b   400000  6.082248  4.568532  375.562569         NaN        NaN   \n",
      "568  0x5b   600000  6.085122  4.563634  374.982853         NaN        NaN   \n",
      "569  0x5b   700000  6.084321  4.565869  375.215809         NaN        NaN   \n",
      "570  0x5b   800000  6.087066  4.574966  375.793654         NaN        NaN   \n",
      "571  0x5b  1000000  6.083627  4.565847  375.256920         NaN        NaN   \n",
      "572  0x5b  1200000  6.084983  4.565373  375.133960         NaN        NaN   \n",
      "573  0x5b  1400000  5.898591  4.724952  400.515281         NaN        NaN   \n",
      "574  0x13   100000  5.413353  3.538540  326.834062         NaN        NaN   \n",
      "575  0x13   200000  5.412244  3.526898  325.825770         NaN        NaN   \n",
      "576  0x13   400000  5.413580  3.509376  324.127020         NaN        NaN   \n",
      "577  0x13   600000  5.413208  3.518169  324.961308         NaN        NaN   \n",
      "578  0x13   700000  5.411627  3.515561  324.815336         NaN        NaN   \n",
      "579  0x13   800000  5.413196  3.514465  324.619885         NaN        NaN   \n",
      "580  0x13  1000000  5.412957  3.513339  324.530285         NaN        NaN   \n",
      "581  0x13  1200000  5.408136  3.511839  324.680753         NaN        NaN   \n",
      "582  0x13  1400000  5.399939  3.513004  325.281687         NaN        NaN   \n",
      "583  0xed   100000  5.955748  5.586214  468.976630         NaN        NaN   \n",
      "584  0xed   200000  5.949501  5.682053  477.523143         NaN        NaN   \n",
      "585  0xed   400000  5.956326  5.701876  478.639989         NaN        NaN   \n",
      "\n",
      "     big_cores  lil_cores  total_cores  core-0  core-1  core-2  core-3  \\\n",
      "0            3          2            5       1       1       1       0   \n",
      "1            3          2            5       1       1       1       0   \n",
      "2            3          2            5       1       1       1       0   \n",
      "3            3          2            5       1       1       1       0   \n",
      "4            3          2            5       1       1       1       0   \n",
      "5            3          2            5       1       1       1       0   \n",
      "6            3          2            5       1       1       1       0   \n",
      "7            3          2            5       1       1       1       0   \n",
      "8            3          2            5       1       1       1       0   \n",
      "9            3          2            5       1       1       0       1   \n",
      "10           3          2            5       1       1       0       1   \n",
      "11           3          2            5       1       1       0       1   \n",
      "12           3          2            5       1       1       0       1   \n",
      "13           3          2            5       1       1       0       1   \n",
      "14           3          2            5       1       1       0       1   \n",
      "15           3          2            5       1       1       0       1   \n",
      "16           3          2            5       1       1       0       1   \n",
      "17           3          2            5       1       1       0       1   \n",
      "18           1          3            4       0       0       1       0   \n",
      "19           1          3            4       0       0       1       0   \n",
      "20           1          3            4       0       0       1       0   \n",
      "21           1          3            4       0       0       1       0   \n",
      "22           1          3            4       0       0       1       0   \n",
      "23           1          3            4       0       0       1       0   \n",
      "24           1          3            4       0       0       1       0   \n",
      "25           1          3            4       0       0       1       0   \n",
      "26           1          3            4       0       0       1       0   \n",
      "27           3          3            6       0       1       1       1   \n",
      "28           3          3            6       0       1       1       1   \n",
      "29           3          3            6       0       1       1       1   \n",
      "..         ...        ...          ...     ...     ...     ...     ...   \n",
      "556          2          3            5       0       1       1       0   \n",
      "557          2          3            5       0       1       1       0   \n",
      "558          2          3            5       0       1       1       0   \n",
      "559          2          3            5       0       1       1       0   \n",
      "560          2          3            5       0       1       1       0   \n",
      "561          2          3            5       0       1       1       0   \n",
      "562          2          3            5       0       1       1       0   \n",
      "563          2          3            5       0       1       1       0   \n",
      "564          2          3            5       0       1       1       0   \n",
      "565          2          3            5       0       1       0       1   \n",
      "566          2          3            5       0       1       0       1   \n",
      "567          2          3            5       0       1       0       1   \n",
      "568          2          3            5       0       1       0       1   \n",
      "569          2          3            5       0       1       0       1   \n",
      "570          2          3            5       0       1       0       1   \n",
      "571          2          3            5       0       1       0       1   \n",
      "572          2          3            5       0       1       0       1   \n",
      "573          2          3            5       0       1       0       1   \n",
      "574          1          2            3       0       0       0       1   \n",
      "575          1          2            3       0       0       0       1   \n",
      "576          1          2            3       0       0       0       1   \n",
      "577          1          2            3       0       0       0       1   \n",
      "578          1          2            3       0       0       0       1   \n",
      "579          1          2            3       0       0       0       1   \n",
      "580          1          2            3       0       0       0       1   \n",
      "581          1          2            3       0       0       0       1   \n",
      "582          1          2            3       0       0       0       1   \n",
      "583          3          3            6       1       1       1       0   \n",
      "584          3          3            6       1       1       1       0   \n",
      "585          3          3            6       1       1       1       0   \n",
      "\n",
      "     core-4  core-5  core-6  core-7  \n",
      "0         0       1       1       0  \n",
      "1         0       1       1       0  \n",
      "2         0       1       1       0  \n",
      "3         0       1       1       0  \n",
      "4         0       1       1       0  \n",
      "5         0       1       1       0  \n",
      "6         0       1       1       0  \n",
      "7         0       1       1       0  \n",
      "8         0       1       1       0  \n",
      "9         1       0       1       0  \n",
      "10        1       0       1       0  \n",
      "11        1       0       1       0  \n",
      "12        1       0       1       0  \n",
      "13        1       0       1       0  \n",
      "14        1       0       1       0  \n",
      "15        1       0       1       0  \n",
      "16        1       0       1       0  \n",
      "17        1       0       1       0  \n",
      "18        1       1       0       1  \n",
      "19        1       1       0       1  \n",
      "20        1       1       0       1  \n",
      "21        1       1       0       1  \n",
      "22        1       1       0       1  \n",
      "23        1       1       0       1  \n",
      "24        1       1       0       1  \n",
      "25        1       1       0       1  \n",
      "26        1       1       0       1  \n",
      "27        1       1       1       0  \n",
      "28        1       1       1       0  \n",
      "29        1       1       1       0  \n",
      "..      ...     ...     ...     ...  \n",
      "556       1       0       1       1  \n",
      "557       1       0       1       1  \n",
      "558       1       0       1       1  \n",
      "559       1       0       1       1  \n",
      "560       1       0       1       1  \n",
      "561       1       0       1       1  \n",
      "562       1       0       1       1  \n",
      "563       1       0       1       1  \n",
      "564       1       0       1       1  \n",
      "565       1       0       1       1  \n",
      "566       1       0       1       1  \n",
      "567       1       0       1       1  \n",
      "568       1       0       1       1  \n",
      "569       1       0       1       1  \n",
      "570       1       0       1       1  \n",
      "571       1       0       1       1  \n",
      "572       1       0       1       1  \n",
      "573       1       0       1       1  \n",
      "574       0       0       1       1  \n",
      "575       0       0       1       1  \n",
      "576       0       0       1       1  \n",
      "577       0       0       1       1  \n",
      "578       0       0       1       1  \n",
      "579       0       0       1       1  \n",
      "580       0       0       1       1  \n",
      "581       0       0       1       1  \n",
      "582       0       0       1       1  \n",
      "583       1       1       0       1  \n",
      "584       1       1       0       1  \n",
      "585       1       1       0       1  \n",
      "\n",
      "[586 rows x 18 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.010239 using {'batch_size': 5, 'epochs': 50, 'init': 'glorot_uniform', 'optimizer': 'rmsprop'}\n",
      "0.010239 (0.014499) with: {'batch_size': 5, 'epochs': 50, 'init': 'glorot_uniform', 'optimizer': 'rmsprop'}\n",
      "0.010239 (0.014499) with: {'batch_size': 5, 'epochs': 50, 'init': 'glorot_uniform', 'optimizer': 'adam'}\n",
      "0.000000 (0.000000) with: {'batch_size': 5, 'epochs': 50, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
      "0.000000 (0.000000) with: {'batch_size': 5, 'epochs': 50, 'init': 'normal', 'optimizer': 'adam'}\n",
      "0.000000 (0.000000) with: {'batch_size': 5, 'epochs': 50, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
      "0.000000 (0.000000) with: {'batch_size': 5, 'epochs': 50, 'init': 'uniform', 'optimizer': 'adam'}\n",
      "0.010239 (0.014499) with: {'batch_size': 5, 'epochs': 100, 'init': 'glorot_uniform', 'optimizer': 'rmsprop'}\n",
      "0.000000 (0.000000) with: {'batch_size': 5, 'epochs': 100, 'init': 'glorot_uniform', 'optimizer': 'adam'}\n",
      "0.010239 (0.014499) with: {'batch_size': 5, 'epochs': 100, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
      "0.000000 (0.000000) with: {'batch_size': 5, 'epochs': 100, 'init': 'normal', 'optimizer': 'adam'}\n",
      "0.000000 (0.000000) with: {'batch_size': 5, 'epochs': 100, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
      "0.000000 (0.000000) with: {'batch_size': 5, 'epochs': 100, 'init': 'uniform', 'optimizer': 'adam'}\n",
      "0.000000 (0.000000) with: {'batch_size': 5, 'epochs': 150, 'init': 'glorot_uniform', 'optimizer': 'rmsprop'}\n",
      "0.000000 (0.000000) with: {'batch_size': 5, 'epochs': 150, 'init': 'glorot_uniform', 'optimizer': 'adam'}\n",
      "0.010239 (0.014499) with: {'batch_size': 5, 'epochs': 150, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
      "0.000000 (0.000000) with: {'batch_size': 5, 'epochs': 150, 'init': 'normal', 'optimizer': 'adam'}\n",
      "0.000000 (0.000000) with: {'batch_size': 5, 'epochs': 150, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
      "0.010239 (0.014499) with: {'batch_size': 5, 'epochs': 150, 'init': 'uniform', 'optimizer': 'adam'}\n",
      "0.010239 (0.014499) with: {'batch_size': 10, 'epochs': 50, 'init': 'glorot_uniform', 'optimizer': 'rmsprop'}\n",
      "0.010239 (0.014499) with: {'batch_size': 10, 'epochs': 50, 'init': 'glorot_uniform', 'optimizer': 'adam'}\n",
      "0.000000 (0.000000) with: {'batch_size': 10, 'epochs': 50, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
      "0.000000 (0.000000) with: {'batch_size': 10, 'epochs': 50, 'init': 'normal', 'optimizer': 'adam'}\n",
      "0.000000 (0.000000) with: {'batch_size': 10, 'epochs': 50, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
      "0.000000 (0.000000) with: {'batch_size': 10, 'epochs': 50, 'init': 'uniform', 'optimizer': 'adam'}\n",
      "0.000000 (0.000000) with: {'batch_size': 10, 'epochs': 100, 'init': 'glorot_uniform', 'optimizer': 'rmsprop'}\n",
      "0.000000 (0.000000) with: {'batch_size': 10, 'epochs': 100, 'init': 'glorot_uniform', 'optimizer': 'adam'}\n",
      "0.000000 (0.000000) with: {'batch_size': 10, 'epochs': 100, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
      "0.000000 (0.000000) with: {'batch_size': 10, 'epochs': 100, 'init': 'normal', 'optimizer': 'adam'}\n",
      "0.000000 (0.000000) with: {'batch_size': 10, 'epochs': 100, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
      "0.000000 (0.000000) with: {'batch_size': 10, 'epochs': 100, 'init': 'uniform', 'optimizer': 'adam'}\n",
      "0.010239 (0.014499) with: {'batch_size': 10, 'epochs': 150, 'init': 'glorot_uniform', 'optimizer': 'rmsprop'}\n",
      "0.000000 (0.000000) with: {'batch_size': 10, 'epochs': 150, 'init': 'glorot_uniform', 'optimizer': 'adam'}\n",
      "0.010239 (0.014499) with: {'batch_size': 10, 'epochs': 150, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
      "0.010239 (0.014499) with: {'batch_size': 10, 'epochs': 150, 'init': 'normal', 'optimizer': 'adam'}\n",
      "0.000000 (0.000000) with: {'batch_size': 10, 'epochs': 150, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
      "0.010239 (0.014499) with: {'batch_size': 10, 'epochs': 150, 'init': 'uniform', 'optimizer': 'adam'}\n",
      "0.010239 (0.014499) with: {'batch_size': 20, 'epochs': 50, 'init': 'glorot_uniform', 'optimizer': 'rmsprop'}\n",
      "0.000000 (0.000000) with: {'batch_size': 20, 'epochs': 50, 'init': 'glorot_uniform', 'optimizer': 'adam'}\n",
      "0.000000 (0.000000) with: {'batch_size': 20, 'epochs': 50, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
      "0.000000 (0.000000) with: {'batch_size': 20, 'epochs': 50, 'init': 'normal', 'optimizer': 'adam'}\n",
      "0.000000 (0.000000) with: {'batch_size': 20, 'epochs': 50, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
      "0.000000 (0.000000) with: {'batch_size': 20, 'epochs': 50, 'init': 'uniform', 'optimizer': 'adam'}\n",
      "0.000000 (0.000000) with: {'batch_size': 20, 'epochs': 100, 'init': 'glorot_uniform', 'optimizer': 'rmsprop'}\n",
      "0.000000 (0.000000) with: {'batch_size': 20, 'epochs': 100, 'init': 'glorot_uniform', 'optimizer': 'adam'}\n",
      "0.000000 (0.000000) with: {'batch_size': 20, 'epochs': 100, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
      "0.010239 (0.014499) with: {'batch_size': 20, 'epochs': 100, 'init': 'normal', 'optimizer': 'adam'}\n",
      "0.000000 (0.000000) with: {'batch_size': 20, 'epochs': 100, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
      "0.000000 (0.000000) with: {'batch_size': 20, 'epochs': 100, 'init': 'uniform', 'optimizer': 'adam'}\n",
      "0.010239 (0.014499) with: {'batch_size': 20, 'epochs': 150, 'init': 'glorot_uniform', 'optimizer': 'rmsprop'}\n",
      "0.000000 (0.000000) with: {'batch_size': 20, 'epochs': 150, 'init': 'glorot_uniform', 'optimizer': 'adam'}\n",
      "0.000000 (0.000000) with: {'batch_size': 20, 'epochs': 150, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
      "0.000000 (0.000000) with: {'batch_size': 20, 'epochs': 150, 'init': 'normal', 'optimizer': 'adam'}\n",
      "0.000000 (0.000000) with: {'batch_size': 20, 'epochs': 150, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
      "0.010239 (0.014499) with: {'batch_size': 20, 'epochs': 150, 'init': 'uniform', 'optimizer': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "# MLP for Pima Indians Dataset with grid search via sklearn\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy\n",
    " \n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(optimizer='rmsprop', init='glorot_uniform'):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=9, kernel_initializer=init, activation='relu'))\n",
    "    model.add(Dense(9, kernel_initializer=init, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer=init, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    " \n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "# load pima indians dataset\n",
    "file_path = '/Users/yzamora/power/all.out'\n",
    "df = pd.read_csv(file_path, sep='\\s+')\n",
    "\n",
    "df = power_analysis.create_col(df)\n",
    "df = df.drop(columns=['cores','WU_PWR_AVG','WU_ENERGY','big_cores','lil_cores','total_cores'])\n",
    "X = df[['freq','core-0','core-1','core-2','core-3','core-4','core-5','core-6','core-7']]\n",
    "y = df['Power']\n",
    "X = X.values\n",
    "Y = y.values\n",
    "\n",
    "# split into input (X) and output (Y) variables\n",
    "#X = dataset[:,0:8]\n",
    "#Y = dataset[:,8]\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "# grid search epochs, batch size and optimizer\n",
    "optimizers = ['rmsprop', 'adam']\n",
    "init = ['glorot_uniform', 'normal', 'uniform']\n",
    "epochs = [50, 100, 150]\n",
    "batches = [5, 10, 20]\n",
    "param_grid = dict(optimizer=optimizers, epochs=epochs, batch_size=batches, init=init)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid)\n",
    "grid_result = grid.fit(X, Y)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
