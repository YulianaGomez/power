{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import forestci as fci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "from scipy import stats\n",
    "from pylab import rcParams\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, \\\n",
    "    GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "max_queried = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(train_size):\n",
    "    X_train_full = X[:train_size]\n",
    "    y_train_full = y[:train_size]\n",
    "    X_test = X[train_size:]\n",
    "    y_test = y[train_size:]\n",
    "    return (X_train_full, y_train_full, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install forestci\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import sklearn.model_selection as xval\n",
    "from sklearn.datasets.mldata import fetch_mldata\n",
    "import forestci as fci\n",
    "\n",
    "class BaseModel(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit_predict(self):\n",
    "        pass\n",
    "\n",
    "class LogModel(BaseModel):\n",
    "\n",
    "    model_type = 'Multinominal Logistic Regression' \n",
    "    \n",
    "    def fit_predict(self, X_train, y_train, X_val, X_test, c_weight):\n",
    "        print ('training multinomial logistic regression')\n",
    "        train_samples = X_train.shape[0]\n",
    "        self.classifier = LogisticRegression(\n",
    "            C=50. / train_samples,\n",
    "            multi_class='multinomial',\n",
    "            penalty='l1',\n",
    "            solver='saga',\n",
    "            tol=0.1,\n",
    "            class_weight=c_weight,\n",
    "            )\n",
    "        self.classifier.fit(X_train, y_train)\n",
    "        self.test_y_predicted = self.classifier.predict(X_test)\n",
    "        self.val_y_predicted = self.classifier.predict(X_val)\n",
    "        return (X_train, X_val, X_test, self.val_y_predicted,\n",
    "                self.test_y_predicted)\n",
    "\n",
    "class RfModel(BaseModel):\n",
    "\n",
    "    model_type = 'Random Forest'\n",
    "    \n",
    "    def fit_predict(self, X_train, y_train, X_val, X_test, c_weight):\n",
    "        print ('training random forest...')\n",
    "        self.predictor = RandomForestRegressor(n_estimators=500, criterion='mse')\n",
    "        self.predictor.fit(X_train, y_train)\n",
    "        self.test_y_predicted = self.predictor.predict(X_test)\n",
    "        self.val_y_predicted = self.predictor.predict(X_val)\n",
    "        return (X_train, X_val, X_test, self.val_y_predicted, self.test_y_predicted)\n",
    "    \n",
    "    def score(self, y_predicted, y_test):\n",
    "        print ('scoring random forest...')\n",
    "        return self.predictor.score(y_predicted, y_test)\n",
    "    \n",
    "    def variance(self, X_train, X_test):\n",
    "        print('variance of data...')\n",
    "        return fci.random_forest_error(self.predictor,X_train,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainModel:\n",
    "\n",
    "    def __init__(self, model_object):        \n",
    "        self.scores = []\n",
    "        self.model_object = model_object()        \n",
    "\n",
    "    def print_model_type(self):\n",
    "        print (self.model_object.model_type)\n",
    "\n",
    "    # we train normally and get probabilities for the validation set. i.e., we use the probabilities to select the most uncertain samples\n",
    "\n",
    "    def train(self, X_train, y_train, X_val, X_test, c_weight):\n",
    "        print ('Train set:', X_train.shape, 'y:', y_train.shape)\n",
    "        print ('Val   set:', X_val.shape)\n",
    "        print ('Test  set:', X_test.shape)\n",
    "        t0 = time.time()\n",
    "        (X_train, X_val, X_test, self.val_y_predicted,\n",
    "         self.test_y_predicted) = \\\n",
    "            self.model_object.fit_predict(X_train, y_train, X_val, X_test, c_weight)\n",
    "        self.run_time = time.time() - t0\n",
    "        return (X_train, X_val, X_test)  # we return them in case we use PCA, with all the other algorithms, this is not needed.\n",
    "\n",
    "    # we want accuracy only for the test set\n",
    "    def get_test_accuracy(self, i, y_test):\n",
    "        \"\"\"\n",
    "        Only Useful for classification models\n",
    "        \"\"\"\n",
    "        classif_rate = np.mean(self.test_y_predicted.ravel() == y_test.ravel()) * 100\n",
    "        self.scores.append(classif_rate)               \n",
    "        print('--------------------------------')\n",
    "        print('Iteration:',i)\n",
    "        print('--------------------------------')\n",
    "        print('y-test set:',y_test.shape)\n",
    "        print('Example run in %.3f s' % self.run_time,'\\n')\n",
    "        print(\"Accuracy rate for %f \" % (classif_rate))\n",
    "        print('--------------------------------')\n",
    "        \n",
    "    def get_test_score(self, i, X_test, y_test):\n",
    "        \"\"\"\n",
    "        Use for regression models\n",
    "        \"\"\"\n",
    "        test_score = self.model_object.score(X_test, y_test) #rsquared value\n",
    "        mse = mean_squared_error(y_test, self.test_y_predicted)\n",
    "        self.scores.append(test_score)\n",
    "        print('--------------------------------')\n",
    "        print('Iteration:',i)\n",
    "        print('--------------------------------')\n",
    "        print('y-test set:',y_test.shape)\n",
    "        print('Example run in %.3f s' % self.run_time,'\\n')\n",
    "        print(\"Score for %f \" % (test_score))\n",
    "        print(\"MSE for %f \" % (mse))\n",
    "        print('--------------------------------')\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We create a modular selection function class representation, 'BaseSelectionFunction' is a base class for various sample selection methods. Using this architecture, you can implement new selection methods and use them in addition or instead of previous methods, for experimental purposes. Our current implementations include random-selection, entropy-selection, margin sampling-selection and minimum standard deviation-selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseSelectionFunction(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def select(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "class RandomSelection(BaseSelectionFunction):\n",
    "\n",
    "    @staticmethod\n",
    "    def select(probas_val, initial_labeled_samples):\n",
    "        random_state = check_random_state(0)\n",
    "        selection = np.random.choice(probas_val.shape[0], initial_labeled_samples, replace=False)\n",
    "\n",
    "#     print('uniques chosen:',np.unique(selection).shape[0],'<= should be equal to:',initial_labeled_samples)\n",
    "\n",
    "        return selection\n",
    "class VarianceSelection(BaseSelectionFunction):\n",
    "    @staticmethod\n",
    "    def select(var_list, initial_labeled_samples):\n",
    "        #import pdb; pdb.set_trace()\n",
    "        selection = (np.argsort(var_list)[::-1])[:initial_labeled_samples]\n",
    "        return selection\n",
    "\n",
    "class EntropySelection(BaseSelectionFunction):\n",
    "\n",
    "    @staticmethod\n",
    "    def select(probas_val, initial_labeled_samples):\n",
    "        #import pdb; pdb.set_trace()\n",
    "        #e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
    "        e = (-probas_val * np.log2(probas_val)).sum()\n",
    "        selection = (np.argsort(e)[::-1])[:initial_labeled_samples]\n",
    "        return selection\n",
    "      \n",
    "      \n",
    "class MarginSamplingSelection(BaseSelectionFunction):\n",
    "\n",
    "    @staticmethod\n",
    "    def select(probas_val, initial_labeled_samples):\n",
    "        #import pdb; pdb.set_trace()\n",
    "        #rev = np.sort(probas_val, axis=1)[:, ::-1]\n",
    "        rev = np.sort(probas_val)[::-1]\n",
    "        values = rev[:, 0] - rev[:, 1]\n",
    "        selection = np.argsort(values)[:initial_labeled_samples]\n",
    "        return selection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a class that is used to normalize using a MinMax Scaler in the range of [0,1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalize(object):\n",
    "    \n",
    "    def normalize(self, X_train, X_val, X_test):\n",
    "        self.scaler = MinMaxScaler()\n",
    "        X_train = self.scaler.fit_transform(X_train)\n",
    "        X_val   = self.scaler.transform(X_val)\n",
    "        X_test  = self.scaler.transform(X_test)\n",
    "        return (X_train, X_val, X_test) \n",
    "    \n",
    "    def inverse(self, X_train, X_val, X_test):\n",
    "        X_train = self.scaler.inverse_transform(X_train)\n",
    "        X_val   = self.scaler.inverse_transform(X_val)\n",
    "        X_test  = self.scaler.inverse_transform(X_test)\n",
    "        return (X_train, X_val, X_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially we would like to get a random sampling from the unlabeled data-pool, this is done using random.choice without replacement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_k_random_samples(initial_labeled_samples, X_train_full, \n",
    "                         y_train_full,index_test_full,index_train_full):\n",
    "    random_state = check_random_state(0)\n",
    "    permutation = np.random.choice(trainset_size,\n",
    "                                   initial_labeled_samples,\n",
    "                                   replace=False)\n",
    "    print ()\n",
    "    print ('initial random chosen samples', permutation.shape)#,permutation)\n",
    "    #import pdb; pdb.set_trace()\n",
    "    X_train = X_train_full[permutation]\n",
    "    y_train = y_train_full[permutation]\n",
    "    X_train = X_train.reshape((X_train.shape[0], -1))\n",
    "    \n",
    "    #getting index split\n",
    "    index_train = index_train_full[permutation]\n",
    "    \n",
    "    bin_count = np.bincount(y_train.astype('int64'))\n",
    "    unique = np.unique(y_train.astype('int64'))\n",
    "    print (\n",
    "        'initial train set:',\n",
    "        X_train.shape,\n",
    "        y_train.shape,\n",
    "        'unique(labels):',\n",
    "        bin_count,\n",
    "        unique,\n",
    "        )\n",
    "    return (permutation, X_train, y_train, index_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the main class that initiates the active-learning process according to the algorithm described in the introduction. In short, we select 'k' random samples, train a model, select the most informative samples, remove from the validation set, query their labels and retrain using those samples until reaching the stop criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TheAlgorithm(object):\n",
    "\n",
    "    scores = []\n",
    "\n",
    "    def __init__(self, initial_labeled_samples, model_object, selection_function):\n",
    "        self.initial_labeled_samples = initial_labeled_samples\n",
    "        self.model_object = model_object\n",
    "        self.sample_selection_function = selection_function\n",
    "        self.x_train = None\n",
    "        self.y_train = None\n",
    "        \n",
    "    def get_data(self):\n",
    "        return (self.x_train,self.y_train, self.index_train)\n",
    "\n",
    "    def run(self, X_train_full, y_train_full, X_test, y_test,index_test_full,index_train_full):\n",
    "\n",
    "        # initialize process by applying base learner to labeled training data set to obtain Classifier\n",
    "\n",
    "        (permutation, X_train, y_train, index_train) = \\\n",
    "            get_k_random_samples(self.initial_labeled_samples,\n",
    "                                 X_train_full, y_train_full,index_test_full,index_train_full)\n",
    "        self.queried = self.initial_labeled_samples\n",
    "        self.samplecount = [self.initial_labeled_samples]\n",
    "\n",
    "        # permutation, X_train, y_train = get_equally_k_random_samples(self.initial_labeled_samples,classes)\n",
    "\n",
    "        # assign the val set the rest of the 'unlabelled' training data\n",
    "\n",
    "        X_val = np.array([])\n",
    "        y_val = np.array([])\n",
    "        X_val = np.copy(X_train_full)\n",
    "        X_val = np.delete(X_val, permutation, axis=0)\n",
    "        y_val = np.copy(y_train_full)\n",
    "        y_val = np.delete(y_val, permutation, axis=0)\n",
    "        \n",
    "        index_val = np.array([])\n",
    "        index_val = np.copy(index_train_full)\n",
    "        index_val = np.delete(index_val, permutation, axis=0)\n",
    "        \n",
    "        print ('val set:', X_val.shape, y_val.shape,index_val.shape, permutation.shape)\n",
    "        print ()\n",
    "\n",
    "        # normalize data\n",
    "\n",
    "        normalizer = Normalize()\n",
    "        X_train, X_val, X_test = normalizer.normalize(X_train, X_val, X_test)   \n",
    "        \n",
    "        self.current_model = TrainModel(self.model_object)\n",
    "        (X_train, X_val, X_test) = self.current_model.train(X_train, y_train, X_val, X_test, 'balanced')\n",
    "        active_iteration = 1\n",
    "        #self.current_model.get_test_accuracy(1, y_test)\n",
    "        self.current_model.get_test_score(1, X_test, y_test)\n",
    "\n",
    "        # fpfn = self.current_model.test_y_predicted.ravel() != y_val.ravel()\n",
    "        # print(fpfn)\n",
    "        # self.fpfncount = []\n",
    "        # self.fpfncount.append(fpfn.sum() / y_test.shape[0] * 100)\n",
    "\n",
    "        while self.queried < max_queried:\n",
    "\n",
    "            active_iteration += 1\n",
    "\n",
    "            # get validation probabilities\n",
    "\n",
    "            y_val_pred = \\\n",
    "                self.current_model.model_object.predictor.predict(X_val)\n",
    "            print ('y_val predicted:',\n",
    "                   self.current_model.val_y_predicted.shape,\n",
    "                   self.current_model.val_y_predicted)\n",
    "            #print ('ipc:', y_val_pred.shape, '\\n',\n",
    "                   #np.argmax(y_val_pred, axis=1))\n",
    "            \n",
    "\n",
    "            # select samples using a selection function\n",
    "\n",
    "            uncertain_samples = \\\n",
    "                self.sample_selection_function.select(y_val_pred, self.initial_labeled_samples)\n",
    "\n",
    "            # normalization needs to be inversed and recalculated based on the new train and test set.\n",
    " \n",
    "            X_train, X_val, X_test = normalizer.inverse(X_train, X_val, X_test)   \n",
    "\n",
    "            # get the uncertain samples from the validation set\n",
    "            #import pdb; pdb.set_trace()\n",
    "            print ('trainset before', X_train.shape, y_train.shape)\n",
    "            X_train = np.concatenate((X_train, X_val[uncertain_samples]))\n",
    "            y_train = np.concatenate((y_train, y_val[uncertain_samples]))\n",
    "            index_train = np.concatenate((index_train, index_val[uncertain_samples])) \n",
    "            \n",
    "            print ('trainset after', X_train.shape, y_train.shape,index_train.shape)\n",
    "            self.samplecount.append(X_train.shape[0])\n",
    "\n",
    "            bin_count = np.bincount(y_train.astype('int64'))\n",
    "            unique = np.unique(y_train.astype('int64'))\n",
    "            print (\n",
    "                'updated train set:',\n",
    "                X_train.shape,\n",
    "                y_train.shape,\n",
    "                'unique(labels):',\n",
    "                bin_count,\n",
    "                unique,\n",
    "                )\n",
    "            print(\"updated index:\",\n",
    "                 index_train.shape)\n",
    "            X_val = np.delete(X_val, uncertain_samples, axis=0)\n",
    "            y_val = np.delete(y_val, uncertain_samples, axis=0)\n",
    "            \n",
    "            index_val = np.delete(index_val, uncertain_samples, axis=0)\n",
    "            print ('val set:', X_val.shape, y_val.shape,index_val.shape)\n",
    "            print ()\n",
    "\n",
    "            # normalize again after creating the 'new' train/test sets\n",
    "            normalizer = Normalize()\n",
    "            X_train, X_val, X_test = normalizer.normalize(X_train, X_val, X_test)               \n",
    "\n",
    "            self.queried += self.initial_labeled_samples\n",
    "            (X_train, X_val, X_test) = self.current_model.train(X_train, y_train, X_val, X_test, 'balanced')\n",
    "            #self.current_model.get_test_accuracy(active_iteration, y_test)\n",
    "            self.current_model.get_test_score(active_iteration, X_test, y_test)\n",
    "            \n",
    "            # Test var\n",
    "        var = self.current_model.model_object.variance(X_train, X_test)\n",
    "        self.x_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.index_train = index_train\n",
    "        #Print indices used\n",
    "        #print('Index values used:',\n",
    "              #index_train)\n",
    "                \n",
    "        print ('final active learning scores',\n",
    "               self.current_model.scores)\n",
    "        print('Variance of X_train', var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We download the data, split to train validation and test, we run the experiment by iterating over all of our training algorithms X all of our selection functions X all possible k's in the range of [10,25,50,125,250]. The accuracy results are kept in a dictionary and pickle-saved to a unique file as soon as the model finishes training - this is crucial when using google colaboratory as it tends to disconnect from time to time. We also limit our training to a maximum of 500 queried samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing P100 Data -PICK P100 METRICS WITH V100 IPC new_df\n",
    "p100_only = False\n",
    "if p100_only:\n",
    "    root_path = '/Users/yzamora/Desktop/ActiveLearningFrameworkTutorial/'\n",
    "    df_P100 = pd.read_csv(root_path + 'p100_all_data.csv', index_col = 0)\n",
    "    df_p100_ipc = df_P100.drop(columns=['shared_utilization','stall_other','single_precision_fu_utilization','architecture','input','application_name','kernelname'])\n",
    "    df_p100_ipc = df_p100_ipc['ipc']\n",
    "    p100_ipc_values = df_p100_ipc.values\n",
    "\n",
    "    df_p100_normd = df_P100.drop(columns=['shared_utilization','stall_other','single_precision_fu_utilization','architecture','input','application_name','kernelname','ipc'])\n",
    "    df_p100_norm = df_p100_normd.values\n",
    "    df_p100_norm = MinMaxScaler().fit_transform(df_p100_norm)\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_P = df_p100_norm\n",
    "    Y_P = p100_ipc_values\n",
    "    index = df_P100.index\n",
    "    # Split the data up in train and test sets\n",
    "    X_train, X_test, y_train, y_test, index_train, index_test = train_test_split(X_P, Y_P, index, test_size=0.33, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PICK P100 METRICS WITH V100 IPC new_df\n",
    "p100_v100IPC = True\n",
    "if p100_v100IPC:\n",
    "    root_path = '/Users/yzamora/Desktop/ActiveLearningFrameworkTutorial/'\n",
    "    df_both100 = pd.read_csv('/Users/yzamora/power/nvidia_gpus/all_apps/new_df.csv', index_col = 0)\n",
    "    df_both100_ipc = df_both100.drop(columns=['shared_utilization','stall_other','single_precision_fu_utilization','architecture','input','application_name','kernelname'])\n",
    "    df_both100_ipc = df_both100_ipc['ipc']\n",
    "    both100_ipc_values = df_both100_ipc.values\n",
    "\n",
    "    df_both100_normd = df_both100.drop(columns=['shared_utilization','stall_other','single_precision_fu_utilization','architecture','input','application_name','kernelname','ipc'])\n",
    "    df_both100_norm = df_both100_normd.values\n",
    "    df_both100_norm = MinMaxScaler().fit_transform(df_both100_norm)\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_both = df_both100_norm\n",
    "    Y_both = both100_ipc_values\n",
    "    index = df_both100.index\n",
    "    # Split the data up in train and test sets\n",
    "    X_train, X_test, y_train, y_test, index_train, index_test = train_test_split(X_both, Y_both, index, test_size=0.33, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13789\n"
     ]
    }
   ],
   "source": [
    "print(index_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset_size = index_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (13789, 112) (13789,)\n",
      "test : (6793, 112) (6793,)\n",
      "unique classes 30419\n",
      "stopping at: 3000\n",
      "Count = 1, using model = RfModel, selection_function = VarianceSelection, k = 500, iteration = 0.\n",
      "\n",
      "initial random chosen samples (500,)\n",
      "initial train set: (500, 112) (500,) unique(labels): [377 123] [0 1]\n",
      "val set: (13289, 112) (13289,) (13289,) (500,)\n",
      "\n",
      "Train set: (500, 112) y: (500,)\n",
      "Val   set: (13289, 112)\n",
      "Test  set: (6793, 112)\n",
      "training random forest...\n",
      "scoring random forest...\n",
      "--------------------------------\n",
      "Iteration: 1\n",
      "--------------------------------\n",
      "y-test set: (6793,)\n",
      "Example run in 6.053 s \n",
      "\n",
      "Score for 0.458461 \n",
      "MSE for 0.092545 \n",
      "--------------------------------\n",
      "y_val predicted: (13289,) [1.17949903 0.88701434 0.4988815  ... 0.48856424 0.50541279 1.28189181]\n",
      "trainset before (500, 112) (500,)\n",
      "trainset after (1000, 112) (1000,) (1000,)\n",
      "updated train set: (1000, 112) (1000,) unique(labels): [612 388] [0 1]\n",
      "updated index: (1000,)\n",
      "val set: (12789, 112) (12789,) (12789,)\n",
      "\n",
      "Train set: (1000, 112) y: (1000,)\n",
      "Val   set: (12789, 112)\n",
      "Test  set: (6793, 112)\n",
      "training random forest...\n",
      "scoring random forest...\n",
      "--------------------------------\n",
      "Iteration: 2\n",
      "--------------------------------\n",
      "y-test set: (6793,)\n",
      "Example run in 13.516 s \n",
      "\n",
      "Score for 0.463941 \n",
      "MSE for 0.091609 \n",
      "--------------------------------\n",
      "y_val predicted: (12789,) [1.11211268 0.89919121 0.51386426 ... 1.01357068 0.511535   0.50885774]\n",
      "trainset before (1000, 112) (1000,)\n",
      "trainset after (1500, 112) (1500,) (1500,)\n",
      "updated train set: (1500, 112) (1500,) unique(labels): [845 655] [0 1]\n",
      "updated index: (1500,)\n",
      "val set: (12289, 112) (12289,) (12289,)\n",
      "\n",
      "Train set: (1500, 112) y: (1500,)\n",
      "Val   set: (12289, 112)\n",
      "Test  set: (6793, 112)\n",
      "training random forest...\n",
      "scoring random forest...\n",
      "--------------------------------\n",
      "Iteration: 3\n",
      "--------------------------------\n",
      "y-test set: (6793,)\n",
      "Example run in 21.932 s \n",
      "\n",
      "Score for 0.464601 \n",
      "MSE for 0.091496 \n",
      "--------------------------------\n",
      "y_val predicted: (12289,) [1.0473522  0.86916094 0.51133186 ... 1.05722011 0.49976679 0.50554171]\n",
      "trainset before (1500, 112) (1500,)\n",
      "trainset after (2000, 112) (2000,) (2000,)\n",
      "updated train set: (2000, 112) (2000,) unique(labels): [1100  900] [0 1]\n",
      "updated index: (2000,)\n",
      "val set: (11789, 112) (11789,) (11789,)\n",
      "\n",
      "Train set: (2000, 112) y: (2000,)\n",
      "Val   set: (11789, 112)\n",
      "Test  set: (6793, 112)\n",
      "training random forest...\n",
      "scoring random forest...\n",
      "--------------------------------\n",
      "Iteration: 4\n",
      "--------------------------------\n",
      "y-test set: (6793,)\n",
      "Example run in 31.913 s \n",
      "\n",
      "Score for 0.464502 \n",
      "MSE for 0.091513 \n",
      "--------------------------------\n",
      "y_val predicted: (11789,) [1.01553424 0.87059308 0.50968244 ... 0.98764841 0.5016871  0.50496161]\n",
      "trainset before (2000, 112) (2000,)\n",
      "trainset after (2500, 112) (2500,) (2500,)\n",
      "updated train set: (2500, 112) (2500,) unique(labels): [1346 1138   16] [0 1 2]\n",
      "updated index: (2500,)\n",
      "val set: (11289, 112) (11289,) (11289,)\n",
      "\n",
      "Train set: (2500, 112) y: (2500,)\n",
      "Val   set: (11289, 112)\n",
      "Test  set: (6793, 112)\n",
      "training random forest...\n",
      "scoring random forest...\n",
      "--------------------------------\n",
      "Iteration: 5\n",
      "--------------------------------\n",
      "y-test set: (6793,)\n",
      "Example run in 44.241 s \n",
      "\n",
      "Score for 0.459901 \n",
      "MSE for 0.092299 \n",
      "--------------------------------\n",
      "y_val predicted: (11289,) [0.97962224 0.86991747 0.51283206 ... 1.0442607  0.5159699  0.50559029]\n",
      "trainset before (2500, 112) (2500,)\n",
      "trainset after (3000, 112) (3000,) (3000,)\n",
      "updated train set: (3000, 112) (3000,) unique(labels): [1585 1399   16] [0 1 2]\n",
      "updated index: (3000,)\n",
      "val set: (10789, 112) (10789,) (10789,)\n",
      "\n",
      "Train set: (3000, 112) y: (3000,)\n",
      "Val   set: (10789, 112)\n",
      "Test  set: (6793, 112)\n",
      "training random forest...\n",
      "scoring random forest...\n",
      "--------------------------------\n",
      "Iteration: 6\n",
      "--------------------------------\n",
      "y-test set: (6793,)\n",
      "Example run in 57.437 s \n",
      "\n",
      "Score for 0.464236 \n",
      "MSE for 0.091559 \n",
      "--------------------------------\n",
      "variance of data...\n",
      "final active learning scores [0.4584612852800081, 0.4639410866837958, 0.4646011922564191, 0.4645019207742659, 0.4599012069910097, 0.46423564603005535]\n",
      "Variance of X_train [0.04874022 0.04488605 0.05265897 ... 0.04073064 0.04833005 0.04054757]\n",
      "saved Active-learning-experiment-1.pkl /Users/yzamora/Desktop/ActiveLearningFrameworkTutorial ['hash_data.ipynb', 'spec_v100_81.csv', 'LICENSE', 'spec_p100_81.csv', 'spec_v100_818.csv', 'indices_size10.txt', 'README.md', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-3.pkl', 'indices_size500_p100_Only.txt', 'spec_p100_2678.csv', 'v100_spec_dataset.ipynb', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-5.pkl', 'indices_size25.txt', 'active_learning_P100.ipynb', '.ipynb_checkpoints', 'indices_size125.txt', 'indices_125.txt', 'Active_Learning_Tutorial.ipynb', '.git', 'indices_size250.txt', 'spec_v100_2678.csv', 'ActiveLearn_P100_V100.ipynb', 'spec_p100_818.csv', 'indices_size50.txt', 'active_learning_P100_new.ipynb', 'p100_all_data.csv']\n",
      "\n",
      " \n",
      " Finalized training set shape:  (3000, 112)\n",
      "\n",
      " \n",
      " Index shape: (3000, 1)\n",
      "\n",
      "---------------------------- FINISHED ---------------------------\n",
      "\n",
      "{'RfModel': {'VarianceSelection': {'500': [[0.4584612852800081, 0.4639410866837958, 0.4646011922564191, 0.4645019207742659, 0.4599012069910097, 0.46423564603005535]]}}}\n",
      "{'RfModel': {'VarianceSelection': {'500': [[0.4584612852800081, 0.4639410866837958, 0.4646011922564191, 0.4645019207742659, 0.4599012069910097, 0.46423564603005535]]}}}\n"
     ]
    }
   ],
   "source": [
    "#(X, y) = download()\n",
    "#(X_train_full, y_train_full, X_test, y_test) = split(trainset_size)\n",
    "\n",
    "X = X_P\n",
    "y = Y_P\n",
    "X_train_full = X_train\n",
    "y_train_full = y_train\n",
    "X_test = X_test\n",
    "y_test = y_test\n",
    "\n",
    "print ('train:', X_train_full.shape, y_train_full.shape)\n",
    "print ('test :', X_test.shape, y_test.shape)\n",
    "classes = len(np.unique(y))\n",
    "print ('unique classes', classes)\n",
    "\n",
    "def pickle_save(fname, data):\n",
    "  filehandler = open(fname,\"wb\")\n",
    "  pickle.dump(data,filehandler)\n",
    "  filehandler.close() \n",
    "  print('saved', fname, os.getcwd(), os.listdir())\n",
    "\n",
    "def pickle_load(fname):\n",
    "  print(os.getcwd(), os.listdir())\n",
    "  file = open(fname,'rb')\n",
    "  data = pickle.load(file)\n",
    "  file.close()\n",
    "  print(data)\n",
    "  return data\n",
    " \n",
    "def experiment(d, models, selection_functions, Ks, repeats, contfrom):\n",
    "    algos_temp = []\n",
    "    print ('stopping at:', max_queried)\n",
    "    count = 0\n",
    "    for model_object in models:\n",
    "      if model_object.__name__ not in d:\n",
    "          d[model_object.__name__] = {}\n",
    "      \n",
    "      for selection_function in selection_functions:\n",
    "        if selection_function.__name__ not in d[model_object.__name__]:\n",
    "            d[model_object.__name__][selection_function.__name__] = {}\n",
    "        \n",
    "        for k in Ks:\n",
    "            d[model_object.__name__][selection_function.__name__][str(k)] = []           \n",
    "            \n",
    "            for i in range(0, repeats):\n",
    "                count+=1\n",
    "                if count >= contfrom:\n",
    "                    print ('Count = %s, using model = %s, selection_function = %s, k = %s, iteration = %s.' % (count, model_object.__name__, selection_function.__name__, k, i))\n",
    "                    alg = TheAlgorithm(k, \n",
    "                                       model_object, \n",
    "                                       selection_function\n",
    "                                       )\n",
    "                    alg.run(X_train_full, y_train_full, X_test, y_test,index_test,index_train)\n",
    "                    d[model_object.__name__][selection_function.__name__][str(k)].append(alg.current_model.scores)\n",
    "                    fname = 'Active-learning-experiment-' + str(count) + '.pkl'\n",
    "                    pickle_save(fname, d)\n",
    "                    \n",
    "                    activelearn_data = alg.get_data()\n",
    "                    \n",
    "                    #import pdb; pdb.set_trace()\n",
    "                    \n",
    "                    #Creating hash for finalized shape\n",
    "                    print(\"\\n \\n Finalized training set shape: \",activelearn_data[0].shape)\n",
    "                    #final_shape = hash_data(pd.DataFrame(activelearn_data[0]))\n",
    "                    print(\"\\n \\n Index shape:\", pd.DataFrame(activelearn_data[2]).shape)\n",
    "                    #Save indices to file\n",
    "                    with open('indices_size'+ str(k) + '_both.txt', 'w') as f:\n",
    "                        for item in activelearn_data[2]:\n",
    "                            f.write(\"%s\\n\" % item)\n",
    "                            \n",
    "                    if count % 5 == 0:\n",
    "                        print(json.dumps(d, indent=2, sort_keys=True))\n",
    "                    print ()\n",
    "                    print ('---------------------------- FINISHED ---------------------------')\n",
    "                    print ()\n",
    "    return d\n",
    "\n",
    "#how do i find final chosen X_train data points\n",
    "repeats = 1\n",
    "models = [RfModel] \n",
    "#selection_functions = [RandomSelection, MarginSamplingSelection, EntropySelection]\n",
    "selection_functions = [VarianceSelection]\n",
    "Ks = [500] #[125,250,50,25,10] \n",
    "d = {}\n",
    "stopped_at = -1 \n",
    "\n",
    "# print('directory dump including pickle files:', os.getcwd(), np.sort(os.listdir()))  \n",
    "# d = pickle_load('Active-learning-experiment-' + str(stopped_at) + '.pkl')  \n",
    "# print(json.dumps(d, indent=2, sort_keys=True))\n",
    "\n",
    "d = experiment(d, models, selection_functions, Ks, repeats, stopped_at+1)\n",
    "\n",
    "print (d)\n",
    "results = json.loads(json.dumps(d, indent=2, sort_keys=True))\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef performance_plot(fully_supervised_accuracy, dic, models, selection_functions, Ks, repeats):  \\n    fig, ax = plt.subplots()\\n    ax.plot([0,500],[fully_supervised_accuracy, fully_supervised_accuracy],label = 'algorithm-upper-bound')\\n    for model_object in models:\\n      for selection_function in selection_functions:\\n        for idx, k in enumerate(Ks):\\n            x = np.arange(float(Ks[idx]), 500 + float(Ks[idx]), float(Ks[idx]))            \\n            Sum = np.array(dic[model_object][selection_function][k][0])\\n            for i in range(1, repeats):\\n                Sum = Sum + np.array(dic[model_object][selection_function][k][i])\\n            mean = Sum / repeats\\n            ax.plot(x, mean ,label = model_object + '-' + selection_function + '-' + str(k))\\n    ax.legend()\\n    ax.set_xlim([50,500])\\n    ax.set_ylim([40,100])\\n    ax.grid(True)\\n    plt.show()\\n\\n#models_str = ['SvmModel', 'RfModel', 'LogModel']\\nmodels_str = ['RfModel']#, 'LogModel']\\n\\n#selection_functions_str = ['RandomSelection', 'MarginSamplingSelection', 'EntropySelection']\\nselection_functions_str = ['RandomSelection']#, 'EntropySelection']\\nKs_str = ['250','125']#,'50','25','10'] \\nrepeats = 1\\nrandom_forest_upper_bound = 97\\nsvm_upper_bound = 94.\\nlog_upper_bound = 92.47\\ntotal_experiments = len(models_str) * len(selection_functions_str) * len(Ks_str) * repeats\\n\\nprint('So which is the better model? under the stopping condition and hyper parameters - random forest is the winner!')\\nperformance_plot(random_forest_upper_bound, d, ['RfModel'] , selection_functions_str, Ks_str, 1)\\n#performance_plot(svm_upper_bound, d, ['SvmModel'] , selection_functions_str    , Ks_str, 1)\\n#performance_plot(log_upper_bound, d, ['LogModel'] , selection_functions_str    , Ks_str, 1)\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def performance_plot(fully_supervised_accuracy, dic, models, selection_functions, Ks, repeats):  \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot([0,500],[fully_supervised_accuracy, fully_supervised_accuracy],label = 'algorithm-upper-bound')\n",
    "    for model_object in models:\n",
    "      for selection_function in selection_functions:\n",
    "        for idx, k in enumerate(Ks):\n",
    "            x = np.arange(float(Ks[idx]), 500 + float(Ks[idx]), float(Ks[idx]))            \n",
    "            Sum = np.array(dic[model_object][selection_function][k][0])\n",
    "            for i in range(1, repeats):\n",
    "                Sum = Sum + np.array(dic[model_object][selection_function][k][i])\n",
    "            mean = Sum / repeats\n",
    "            ax.plot(x, mean ,label = model_object + '-' + selection_function + '-' + str(k))\n",
    "    ax.legend()\n",
    "    ax.set_xlim([50,500])\n",
    "    ax.set_ylim([40,100])\n",
    "    ax.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "#models_str = ['SvmModel', 'RfModel', 'LogModel']\n",
    "models_str = ['RfModel']#, 'LogModel']\n",
    "\n",
    "#selection_functions_str = ['RandomSelection', 'MarginSamplingSelection', 'EntropySelection']\n",
    "selection_functions_str = ['RandomSelection']#, 'EntropySelection']\n",
    "Ks_str = ['250','125']#,'50','25','10'] \n",
    "repeats = 1\n",
    "random_forest_upper_bound = 97\n",
    "svm_upper_bound = 94.\n",
    "log_upper_bound = 92.47\n",
    "total_experiments = len(models_str) * len(selection_functions_str) * len(Ks_str) * repeats\n",
    "\n",
    "print('So which is the better model? under the stopping condition and hyper parameters - random forest is the winner!')\n",
    "performance_plot(random_forest_upper_bound, d, ['RfModel'] , selection_functions_str, Ks_str, 1)\n",
    "#performance_plot(svm_upper_bound, d, ['SvmModel'] , selection_functions_str    , Ks_str, 1)\n",
    "#performance_plot(log_upper_bound, d, ['LogModel'] , selection_functions_str    , Ks_str, 1)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
