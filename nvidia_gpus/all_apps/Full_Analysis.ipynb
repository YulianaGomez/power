{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing performance data, initial cleaning, converting data into dictionary (combined_data_), datafram with dropped kernel name for analysis (df2), and normalized data (X) to be used in later analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/Cellar/python/3.6.4_4/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/local/Cellar/python/3.6.4_4/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "from keras.layers import Input,Dense\n",
    "from keras.models import Model,Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import optimizers\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import csv\n",
    "import os.path\n",
    "\n",
    "# Step 1 - Process Data:\n",
    "\n",
    "save_fname = \"saved_data\"\n",
    "if os.path.isfile(save_fname+\".npy\"):\n",
    "    print(\"Loading saved X data.\")\n",
    "    X = np.load(save_fname+\".npy\")\n",
    "\n",
    "else:\n",
    "    #calculating number of kernels total\n",
    "    kernel_count = 0\n",
    "    total_kernels = []\n",
    "    combined_data_ = {}\n",
    "    target_kernels = []\n",
    "    metric_targets = []\n",
    "    all_sig_metrics = []\n",
    "    for filen_ in glob.glob(\"/Users/yzamora/Desktop/all_data/*.csv\"):\n",
    "\n",
    "        filen = os.path.basename(filen_)\n",
    "        filen_split = filen.split('.')[0].split('_')\n",
    "        bench_name = filen_split[1]\n",
    "        architecture = filen_split[0]\n",
    "        unique_spec = filen_split[2]\n",
    "        \n",
    "        key_root = bench_name\n",
    "        levels = [\"Idle\", \"Low\",\"High\", \"Max\"]\n",
    "        bw_units = [\"GB\", \"MB\", \"KB\" ,\"0B\"]\n",
    "\n",
    "        # Now open the file and look for the data\n",
    "        with open(filen_ ,'r') as file_handle:\n",
    "\n",
    "            data_found = False\n",
    "            ncols = 1\n",
    "            fdata = csv.reader(file_handle)\n",
    "            index_lookup = {}\n",
    "            for line_split in fdata:\n",
    "\n",
    "                lsplt = (len(line_split) > 0)\n",
    "\n",
    "                if data_found:\n",
    "\n",
    "                    if lsplt and len(line_split) == ncols:\n",
    "\n",
    "                        # Read in desired value for the current metric\n",
    "                        target_index = index_lookup['Avg']; value = 0\n",
    "                        metric_name = line_split[index_lookup['Metric Name']]\n",
    "                        if line_split[target_index].isdecimal():\n",
    "                            if line_split[target_index]!= '0':\n",
    "\n",
    "                                all_sig_metrics.append(metric_name)\n",
    "                                value = int(line_split[ target_index ])\n",
    "\n",
    "                            # Labeled with percentage\n",
    "                        elif \"%\" == line_split[target_index][-1]:\n",
    "                            #print (\"percentage loop\")\n",
    "                            all_sig_metrics.append(metric_name)\n",
    "                            value = float(line_split[ target_index ][0:7]) / 100.0\n",
    "\n",
    "                        # Labeled with bandwidth units\n",
    "                        elif line_split[ target_index ][-4:-2] in bw_units:\n",
    "                            # Just take the first\n",
    "                            units = line_split[ target_index ][-4:-2]\n",
    "                            all_sig_metrics.append(metric_name)\n",
    "                            mfact = 1.0\n",
    "                            if   units == \"KB\": mfact = 1024\n",
    "                            elif units == \"MB\": mfact = 1024*1024\n",
    "                            elif units == \"GB\": mfact = 1024*1024*1024\n",
    "                            elif units == \"0B\":  mfact = 1\n",
    "                            value = float(line_split[ target_index ][0:7]) * mfact\n",
    "\n",
    "                        # idle, low, max\n",
    "                        elif line_split[ target_index ][-1] == \")\":\n",
    "                            #print (\"low\")\n",
    "                            all_sig_metrics.append(metric_name)\n",
    "                            value = int(line_split[ target_index].split('(')[1].split(\")\")[0])\n",
    "\n",
    "                        # otherwise, float\n",
    "                        else:\n",
    "                            value = float(line_split[ target_index ])\n",
    "\n",
    "                         # Parse name of kernel\n",
    "                        kernel_name = line_split[ index_lookup['Kernel'] ].split('(')[0]\n",
    "                        if not(kernel_name in total_kernels):\n",
    "                            total_kernels.append(kernel_name)\n",
    "                            kernel_count += 1\n",
    "\n",
    "                        # Define kernel-specific key\n",
    "                        key = key_root + architecture + \"_\" + unique_spec + \"_\" + kernel_name\n",
    "\n",
    "                        # Initialize dict for this key, if it is new\n",
    "                        if not (key in combined_data_):\n",
    "                            combined_data_ [ key ] = {}\n",
    "                        if not (kernel_name in target_kernels):\n",
    "                            target_kernels.append(kernel_name)\n",
    "\n",
    "                        # Store value for the metric being read right now\n",
    "                        combined_data_[key][ metric_name ] = value\n",
    "                        combined_data_[key][\"kernelname\"] = kernel_name\n",
    "\n",
    "                    else:\n",
    "                        data_found = False\n",
    "\n",
    "\n",
    "                elif lsplt and line_split[0] == 'Device' and line_split[1] == 'Kernel':\n",
    "                    # Set flag that we are at the data:\n",
    "                    data_found = True\n",
    "                    # Set number of columns in table:\n",
    "                    ncols = len(line_split)\n",
    "                    # Generate an index lookup table:\n",
    "                    idx = 0\n",
    "                    for term in line_split:\n",
    "                        index_lookup[term] = idx\n",
    "                        idx += 1\n",
    "    #from sklearn.preprocessing import scale\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "    df = pd.DataFrame.from_dict(combined_data_,orient='index')\n",
    "    df = df.dropna(axis=1,how='any')\n",
    "    df2 = df.drop(columns=['kernelname'])\n",
    "    data = df2.values #scale(df2.values)\n",
    "    #X = StandardScaler().fit_transform(data)\n",
    "    X = MinMaxScaler().fit_transform(data)\n",
    "    #X=X.astype('float32')/float(X.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 13866 data points.\n",
      "There are 118 features.\n",
      "There are 29 kernels tested.\n"
     ]
    }
   ],
   "source": [
    "print(\"There are %i data points.\" % len(X))\n",
    "print(\"There are %i features.\" % len(X[0]))\n",
    "print(\"There are %i kernels tested.\" % kernel_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
