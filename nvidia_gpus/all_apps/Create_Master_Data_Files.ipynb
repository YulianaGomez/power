{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Generating the Master Dataset Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inst_per_warp</th>\n",
       "      <th>kernelname</th>\n",
       "      <th>branch_efficiency</th>\n",
       "      <th>warp_execution_efficiency</th>\n",
       "      <th>warp_nonpred_execution_efficiency</th>\n",
       "      <th>inst_replay_overhead</th>\n",
       "      <th>shared_load_transactions_per_request</th>\n",
       "      <th>shared_store_transactions_per_request</th>\n",
       "      <th>local_load_transactions_per_request</th>\n",
       "      <th>local_store_transactions_per_request</th>\n",
       "      <th>...</th>\n",
       "      <th>single_precision_fu_utilization</th>\n",
       "      <th>double_precision_fu_utilization</th>\n",
       "      <th>flop_hp_efficiency</th>\n",
       "      <th>flop_sp_efficiency</th>\n",
       "      <th>flop_dp_efficiency</th>\n",
       "      <th>sysmem_read_utilization</th>\n",
       "      <th>sysmem_write_utilization</th>\n",
       "      <th>architecture</th>\n",
       "      <th>application_name</th>\n",
       "      <th>input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56.00056</td>\n",
       "      <td>bpnn_adjust_weights_cuda</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.002058</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047434</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>P100</td>\n",
       "      <td>backprop</td>\n",
       "      <td>-100000_bpnn_adjust_weights_cuda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>184.00000</td>\n",
       "      <td>bpnn_layerforward_CUDA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.943953</td>\n",
       "      <td>0.761888</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.696429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004695</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>P100</td>\n",
       "      <td>backprop</td>\n",
       "      <td>-100000_bpnn_layerforward_CUDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56.00560</td>\n",
       "      <td>bpnn_adjust_weights_cuda</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.999948</td>\n",
       "      <td>0.016234</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043993</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>P100</td>\n",
       "      <td>backprop</td>\n",
       "      <td>-10000_bpnn_adjust_weights_cuda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>184.00000</td>\n",
       "      <td>bpnn_layerforward_CUDA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.943953</td>\n",
       "      <td>0.761888</td>\n",
       "      <td>0.006918</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.696429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003017</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>P100</td>\n",
       "      <td>backprop</td>\n",
       "      <td>-10000_bpnn_layerforward_CUDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56.00056</td>\n",
       "      <td>bpnn_adjust_weights_cuda</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.002492</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.048306</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>P100</td>\n",
       "      <td>backprop</td>\n",
       "      <td>-100016_bpnn_adjust_weights_cuda</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 120 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   inst_per_warp                kernelname  branch_efficiency  \\\n",
       "0       56.00056  bpnn_adjust_weights_cuda                1.0   \n",
       "1      184.00000    bpnn_layerforward_CUDA                1.0   \n",
       "2       56.00560  bpnn_adjust_weights_cuda                1.0   \n",
       "3      184.00000    bpnn_layerforward_CUDA                1.0   \n",
       "4       56.00056  bpnn_adjust_weights_cuda                1.0   \n",
       "\n",
       "   warp_execution_efficiency  warp_nonpred_execution_efficiency  \\\n",
       "0                   0.999995                           0.999994   \n",
       "1                   0.943953                           0.761888   \n",
       "2                   0.999950                           0.999948   \n",
       "3                   0.943953                           0.761888   \n",
       "4                   0.999995                           0.999994   \n",
       "\n",
       "   inst_replay_overhead  shared_load_transactions_per_request  \\\n",
       "0              0.002058                              0.000000   \n",
       "1              0.000633                              0.645833   \n",
       "2              0.016234                              0.000000   \n",
       "3              0.006918                              0.645833   \n",
       "4              0.002492                              0.000000   \n",
       "\n",
       "   shared_store_transactions_per_request  local_load_transactions_per_request  \\\n",
       "0                               0.000000                                  0.0   \n",
       "1                               0.696429                                  0.0   \n",
       "2                               0.000000                                  0.0   \n",
       "3                               0.696429                                  0.0   \n",
       "4                               0.000000                                  0.0   \n",
       "\n",
       "   local_store_transactions_per_request                ...                 \\\n",
       "0                                   0.0                ...                  \n",
       "1                                   0.0                ...                  \n",
       "2                                   0.0                ...                  \n",
       "3                                   0.0                ...                  \n",
       "4                                   0.0                ...                  \n",
       "\n",
       "   single_precision_fu_utilization  double_precision_fu_utilization  \\\n",
       "0                                2                                1   \n",
       "1                                6                                0   \n",
       "2                                3                                2   \n",
       "3                                6                                0   \n",
       "4                                2                                1   \n",
       "\n",
       "   flop_hp_efficiency  flop_sp_efficiency  flop_dp_efficiency  \\\n",
       "0                 0.0            0.000000            0.047434   \n",
       "1                 0.0            0.004695            0.000000   \n",
       "2                 0.0            0.000000            0.043993   \n",
       "3                 0.0            0.003017            0.000000   \n",
       "4                 0.0            0.000000            0.048306   \n",
       "\n",
       "   sysmem_read_utilization  sysmem_write_utilization  architecture  \\\n",
       "0                        0                         1          P100   \n",
       "1                        0                         1          P100   \n",
       "2                        0                         1          P100   \n",
       "3                        0                         1          P100   \n",
       "4                        0                         1          P100   \n",
       "\n",
       "   application_name                             input  \n",
       "0          backprop  -100000_bpnn_adjust_weights_cuda  \n",
       "1          backprop    -100000_bpnn_layerforward_CUDA  \n",
       "2          backprop   -10000_bpnn_adjust_weights_cuda  \n",
       "3          backprop     -10000_bpnn_layerforward_CUDA  \n",
       "4          backprop  -100016_bpnn_adjust_weights_cuda  \n",
       "\n",
       "[5 rows x 120 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read in master CSV file\n",
    "df = pd.read_csv('mem_bound_all_data.csv', index_col = 0)\n",
    "\n",
    "# Drop columns with NaN\n",
    "df = df.dropna(axis=1,how='any')\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inst_per_warp</th>\n",
       "      <th>kernelname</th>\n",
       "      <th>branch_efficiency</th>\n",
       "      <th>warp_execution_efficiency</th>\n",
       "      <th>warp_nonpred_execution_efficiency</th>\n",
       "      <th>inst_replay_overhead</th>\n",
       "      <th>shared_load_transactions_per_request</th>\n",
       "      <th>shared_store_transactions_per_request</th>\n",
       "      <th>local_load_transactions_per_request</th>\n",
       "      <th>local_store_transactions_per_request</th>\n",
       "      <th>...</th>\n",
       "      <th>double_precision_fu_utilization</th>\n",
       "      <th>flop_hp_efficiency</th>\n",
       "      <th>flop_sp_efficiency</th>\n",
       "      <th>flop_dp_efficiency</th>\n",
       "      <th>sysmem_read_utilization</th>\n",
       "      <th>sysmem_write_utilization</th>\n",
       "      <th>architecture</th>\n",
       "      <th>application_name</th>\n",
       "      <th>input</th>\n",
       "      <th>memory_bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56.00056</td>\n",
       "      <td>bpnn_adjust_weights_cuda</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.002058</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047434</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>P100</td>\n",
       "      <td>backprop</td>\n",
       "      <td>-100000_bpnn_adjust_weights_cuda</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>184.00000</td>\n",
       "      <td>bpnn_layerforward_CUDA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.943953</td>\n",
       "      <td>0.761888</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.696429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004695</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>P100</td>\n",
       "      <td>backprop</td>\n",
       "      <td>-100000_bpnn_layerforward_CUDA</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56.00560</td>\n",
       "      <td>bpnn_adjust_weights_cuda</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.999948</td>\n",
       "      <td>0.016234</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043993</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>P100</td>\n",
       "      <td>backprop</td>\n",
       "      <td>-10000_bpnn_adjust_weights_cuda</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>184.00000</td>\n",
       "      <td>bpnn_layerforward_CUDA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.943953</td>\n",
       "      <td>0.761888</td>\n",
       "      <td>0.006918</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.696429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003017</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>P100</td>\n",
       "      <td>backprop</td>\n",
       "      <td>-10000_bpnn_layerforward_CUDA</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56.00056</td>\n",
       "      <td>bpnn_adjust_weights_cuda</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.002492</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.048306</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>P100</td>\n",
       "      <td>backprop</td>\n",
       "      <td>-100016_bpnn_adjust_weights_cuda</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   inst_per_warp                kernelname  branch_efficiency  \\\n",
       "0       56.00056  bpnn_adjust_weights_cuda                1.0   \n",
       "1      184.00000    bpnn_layerforward_CUDA                1.0   \n",
       "2       56.00560  bpnn_adjust_weights_cuda                1.0   \n",
       "3      184.00000    bpnn_layerforward_CUDA                1.0   \n",
       "4       56.00056  bpnn_adjust_weights_cuda                1.0   \n",
       "\n",
       "   warp_execution_efficiency  warp_nonpred_execution_efficiency  \\\n",
       "0                   0.999995                           0.999994   \n",
       "1                   0.943953                           0.761888   \n",
       "2                   0.999950                           0.999948   \n",
       "3                   0.943953                           0.761888   \n",
       "4                   0.999995                           0.999994   \n",
       "\n",
       "   inst_replay_overhead  shared_load_transactions_per_request  \\\n",
       "0              0.002058                              0.000000   \n",
       "1              0.000633                              0.645833   \n",
       "2              0.016234                              0.000000   \n",
       "3              0.006918                              0.645833   \n",
       "4              0.002492                              0.000000   \n",
       "\n",
       "   shared_store_transactions_per_request  local_load_transactions_per_request  \\\n",
       "0                               0.000000                                  0.0   \n",
       "1                               0.696429                                  0.0   \n",
       "2                               0.000000                                  0.0   \n",
       "3                               0.696429                                  0.0   \n",
       "4                               0.000000                                  0.0   \n",
       "\n",
       "   local_store_transactions_per_request      ...       \\\n",
       "0                                   0.0      ...        \n",
       "1                                   0.0      ...        \n",
       "2                                   0.0      ...        \n",
       "3                                   0.0      ...        \n",
       "4                                   0.0      ...        \n",
       "\n",
       "   double_precision_fu_utilization  flop_hp_efficiency  flop_sp_efficiency  \\\n",
       "0                                1                 0.0            0.000000   \n",
       "1                                0                 0.0            0.004695   \n",
       "2                                2                 0.0            0.000000   \n",
       "3                                0                 0.0            0.003017   \n",
       "4                                1                 0.0            0.000000   \n",
       "\n",
       "   flop_dp_efficiency  sysmem_read_utilization  sysmem_write_utilization  \\\n",
       "0            0.047434                        0                         1   \n",
       "1            0.000000                        0                         1   \n",
       "2            0.043993                        0                         1   \n",
       "3            0.000000                        0                         1   \n",
       "4            0.048306                        0                         1   \n",
       "\n",
       "   architecture  application_name                             input  \\\n",
       "0          P100          backprop  -100000_bpnn_adjust_weights_cuda   \n",
       "1          P100          backprop    -100000_bpnn_layerforward_CUDA   \n",
       "2          P100          backprop   -10000_bpnn_adjust_weights_cuda   \n",
       "3          P100          backprop     -10000_bpnn_layerforward_CUDA   \n",
       "4          P100          backprop  -100016_bpnn_adjust_weights_cuda   \n",
       "\n",
       "   memory_bound  \n",
       "0         False  \n",
       "1         False  \n",
       "2         False  \n",
       "3         False  \n",
       "4         False  \n",
       "\n",
       "[5 rows x 121 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define peak memory bandwidth p100 732\n",
    "peak_mem_bw = {\n",
    "    \"V100\": 898.048 * (1024*1024*1024),\n",
    "    \"P100\": 749.0 * (1024*1024*1024),\n",
    "}\n",
    "mem_bw_thresh = 0.75\n",
    "\n",
    "# Add a column specifying if the case is memory bound\n",
    "df_archs = []\n",
    "for arch in peak_mem_bw.keys():\n",
    "    df_tmp = df[df[\"architecture\"] == arch].copy()\n",
    "    new_col = (\n",
    "        df_tmp[\"dram_read_throughput\"] + df_tmp[\"dram_write_throughput\"]\n",
    "    ) / peak_mem_bw[arch]\n",
    "    new_col = new_col > mem_bw_thresh\n",
    "    df_tmp[\"memory_bound\"] = new_col\n",
    "    df_archs.append(df_tmp.copy())\n",
    "df_merged = pd.concat(df_archs).sort_index()\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert bool \"memory_bound\" column to integers\n",
    "df_merged[\"memory_bound\"]= df_merged[\"memory_bound\"].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we have our master dataframe (df_merged).\n",
    "# Assume the numerical data from this dataframe is used to\n",
    "# scale everything (also leave out `memory_bound` column).\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Helper funciton to return non-numerical column list\n",
    "def _get_string_cols(df_in, str_cols=None):\n",
    "    # Automatically detect non numerical columns\n",
    "    str_cols = str_cols or []\n",
    "    for col in df_in:\n",
    "        if df_in[col].dtype == 'object':\n",
    "            str_cols.append(col)\n",
    "    return str_cols\n",
    "        \n",
    "# Convert numerical columns to out training/test\n",
    "drop_cols = _get_string_cols(df_merged, ['memory_bound'])\n",
    "df_col_ref = df_merged.drop(drop_cols, axis=1)\n",
    "data_to_scale = df_col_ref.values\n",
    "scaler = StandardScaler().fit(data_to_scale)\n",
    "scaled_data_ = scaler.transform(data_to_scale)\n",
    "\n",
    "# Add column to df_merged called 'master_index'\n",
    "df_merged['master_index'] = [int(i) for i in range(len(df_merged.index))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>master_index_V100</th>\n",
       "      <th>master_index_P100</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique_index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bpnn_adjust_weights_cuda_-100000_bpnn_adjust_weights_cuda</th>\n",
       "      <td>19996</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bpnn_layerforward_CUDA_-100000_bpnn_layerforward_CUDA</th>\n",
       "      <td>19997</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bpnn_adjust_weights_cuda_-10000_bpnn_adjust_weights_cuda</th>\n",
       "      <td>19998</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bpnn_layerforward_CUDA_-10000_bpnn_layerforward_CUDA</th>\n",
       "      <td>19999</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bpnn_adjust_weights_cuda_-100016_bpnn_adjust_weights_cuda</th>\n",
       "      <td>20000</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    master_index_V100  \\\n",
       "unique_index                                                            \n",
       "bpnn_adjust_weights_cuda_-100000_bpnn_adjust_we...              19996   \n",
       "bpnn_layerforward_CUDA_-100000_bpnn_layerforwar...              19997   \n",
       "bpnn_adjust_weights_cuda_-10000_bpnn_adjust_wei...              19998   \n",
       "bpnn_layerforward_CUDA_-10000_bpnn_layerforward...              19999   \n",
       "bpnn_adjust_weights_cuda_-100016_bpnn_adjust_we...              20000   \n",
       "\n",
       "                                                    master_index_P100  \n",
       "unique_index                                                           \n",
       "bpnn_adjust_weights_cuda_-100000_bpnn_adjust_we...                0.0  \n",
       "bpnn_layerforward_CUDA_-100000_bpnn_layerforwar...                1.0  \n",
       "bpnn_adjust_weights_cuda_-10000_bpnn_adjust_wei...                2.0  \n",
       "bpnn_layerforward_CUDA_-10000_bpnn_layerforward...                3.0  \n",
       "bpnn_adjust_weights_cuda_-100016_bpnn_adjust_we...                4.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets create a dataframe (df_joined) with each row\n",
    "# corresponding to a specific type of run.\n",
    "# The V100 and P100 metrics are included in the same row,\n",
    "# with `_V100` appended to the metric label for V100, etc.\n",
    "# This means we have 2x the number of metrics for each row.\n",
    "base = 'V100'\n",
    "other = 'P100'\n",
    "\n",
    "df_all = df_merged.copy()\n",
    "unique_col = [] #column that has matches of kernels run on both architectures\n",
    "for k, i in zip(df_all['kernelname'].values, df_all['input'].values):\n",
    "    unique_col.append(k+'_'+i)\n",
    "df_all['unique_index'] = unique_col\n",
    "df_all.set_index('unique_index', inplace=True)\n",
    "\n",
    "# Create 'base' and 'other' dataframes for join\n",
    "df_b = df_all[df_all['architecture'] == base].copy()\n",
    "df_o = df_all[df_all['architecture'] == other].copy()\n",
    "\n",
    "# Final join operation, and drop rows with NaN elements\n",
    "df_joined = df_b.join(df_o, lsuffix='_'+base, rsuffix='_'+other)\n",
    "df_joined = df_joined.dropna(axis=0,how='any')\n",
    "df_joined[['master_index_V100','master_index_P100']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_merged.shape (78330, 122)\n",
      "scaled_data_.shape (78330, 116)\n",
      "df_joined.shape (32291, 244)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inst_per_warp</th>\n",
       "      <th>branch_efficiency</th>\n",
       "      <th>warp_execution_efficiency</th>\n",
       "      <th>warp_nonpred_execution_efficiency</th>\n",
       "      <th>inst_replay_overhead</th>\n",
       "      <th>shared_load_transactions_per_request</th>\n",
       "      <th>shared_store_transactions_per_request</th>\n",
       "      <th>local_load_transactions_per_request</th>\n",
       "      <th>local_store_transactions_per_request</th>\n",
       "      <th>gld_transactions_per_request</th>\n",
       "      <th>...</th>\n",
       "      <th>cf_fu_utilization</th>\n",
       "      <th>special_fu_utilization</th>\n",
       "      <th>half_precision_fu_utilization</th>\n",
       "      <th>single_precision_fu_utilization</th>\n",
       "      <th>double_precision_fu_utilization</th>\n",
       "      <th>flop_hp_efficiency</th>\n",
       "      <th>flop_sp_efficiency</th>\n",
       "      <th>flop_dp_efficiency</th>\n",
       "      <th>sysmem_read_utilization</th>\n",
       "      <th>sysmem_write_utilization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 116 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [inst_per_warp, branch_efficiency, warp_execution_efficiency, warp_nonpred_execution_efficiency, inst_replay_overhead, shared_load_transactions_per_request, shared_store_transactions_per_request, local_load_transactions_per_request, local_store_transactions_per_request, gld_transactions_per_request, gst_transactions_per_request, shared_store_transactions, shared_load_transactions, local_load_transactions, local_store_transactions, gld_transactions, gst_transactions, sysmem_read_transactions, sysmem_write_transactions, l2_read_transactions, l2_write_transactions, dram_read_transactions, dram_write_transactions, global_hit_rate, local_hit_rate, gld_requested_throughput, gst_requested_throughput, gld_throughput, gst_throughput, local_memory_overhead, tex_cache_hit_rate, l2_tex_read_hit_rate, l2_tex_write_hit_rate, dram_read_throughput, dram_write_throughput, tex_cache_throughput, l2_tex_read_throughput, l2_tex_write_throughput, l2_read_throughput, l2_write_throughput, sysmem_read_throughput, sysmem_write_throughput, local_load_throughput, local_store_throughput, shared_load_throughput, shared_store_throughput, gst_efficiency, tex_cache_transactions, flop_count_dp, flop_count_dp_add, flop_count_dp_fma, flop_count_dp_mul, flop_count_sp, flop_count_sp_add, flop_count_sp_fma, flop_count_sp_mul, flop_count_sp_special, inst_executed, inst_issued, dram_utilization, sysmem_utilization, stall_inst_fetch, stall_exec_dependency, stall_memory_dependency, stall_texture, stall_sync, stall_other, stall_constant_memory_dependency, stall_pipe_busy, shared_efficiency, inst_fp_32, inst_fp_64, inst_integer, inst_bit_convert, inst_control, inst_compute_ld_st, inst_misc, inst_inter_thread_communication, issue_slots, cf_issued, cf_executed, ldst_issued, ldst_executed, atomic_transactions, atomic_transactions_per_request, l2_atomic_throughput, l2_atomic_transactions, l2_tex_read_transactions, stall_memory_throttle, stall_not_selected, l2_tex_write_transactions, flop_count_hp, flop_count_hp_add, flop_count_hp_mul, flop_count_hp_fma, inst_fp_16, ipc, issued_ipc, issue_slot_utilization, sm_efficiency, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 116 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We now have our \"master\" dataframe with all of our data\n",
    "# in one place.  In `df_merged` each row corresponds to a\n",
    "# distinct run on a distinct architecture\n",
    "print(\"df_merged.shape\", df_merged.shape)\n",
    "\n",
    "# `scaled_data_` now has our scaled data representation\n",
    "# of all numerical data in `df_merged`.\n",
    "# The row index of the 2-D numpy array is the same as\n",
    "# the 'master_index' column of `df_merged`\n",
    "print(\"scaled_data_.shape\", scaled_data_.shape)\n",
    "\n",
    "# Each row of `df_joined` has corresponds to a specific\n",
    "# type of run (kernel + input), with both architectures\n",
    "# stored in the same row. All column labels are appended\n",
    "# with the name of the architecture (e.g. `'_V100'`)\n",
    "# This means we have 2x the number of metrics for each row.\n",
    "# Note: Column `'master_index_V100'` corresponds to the row\n",
    "# in \"scaled_data_\" for V100 (same for '_P100')\n",
    "print(\"df_joined.shape\", df_joined.shape)\n",
    "\n",
    "# We are assuming here that the columns of `df_col_ref`\n",
    "# are ordered in the same way as `scaled_data_`.\n",
    "df_col_ref[:0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save df_merged to 'df_master.parquet'\n",
    "df_merged.to_parquet('df_master.parquet')\n",
    "\n",
    "# Save df_joined to 'df_master_joined.parquet'\n",
    "df_joined.to_parquet('df_master_joined.parquet')\n",
    "\n",
    "# Save df_col_ref to 'df_column_reference.parquet'\n",
    "df_col_ref[:0].to_parquet('df_column_reference.parquet')\n",
    "\n",
    "# Save scaled_data_ to 'master_scaled_data.npy'\n",
    "np.save('master_scaled_data.npy', scaled_data_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Using the Master Dataset Files\n",
    "\n",
    "The code in \"Part 1\" does not need to be repeated in the future, because we wrote the primary results into persistent files (unless you want to add data to your master dataset, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78330, 122)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Master dataframe with all columns, including `memory_bound` and `master_index`.\n",
    "# Each row corresponds to distinct architecture and run\n",
    "\n",
    "df_master = pd.read_parquet('df_master.parquet')\n",
    "df_master.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32291, 244)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combining V100 and P100 on same row for same run\n",
    "# We are deleting cases where there is no run for either of the architectures\n",
    "# Every column name is appended with the name of the architecture (e.g. \"_V100\");\n",
    "# This includes the `master_index` (e.g `master_index_V100`)\n",
    "\n",
    "df_joined = pd.read_parquet('df_master_joined.parquet')\n",
    "df_joined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 116)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is an \"empty\" dataframe (meaning no rows), containing\n",
    "# column names for numerical data only.\n",
    "# The column nmaes can be used to index the columns of the\n",
    "# scaled data (in master_scaled_data.npy)\n",
    "\n",
    "df_columns_only = pd.read_parquet('df_column_reference.parquet')\n",
    "df_columns_only.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78330, 116)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is a 2-D numpy array corresponding to the numerical data in 'df_master.parquet'\n",
    "# The data has been scaled using the StandardScaler in scikitlearn\n",
    "\n",
    "# Notes: \n",
    "#   - The row indices correspond to the `master_index` column of 'df_master.parquet'\n",
    "#   - The columns correspond to the columns in 'df_column_reference.parquet'.\n",
    "#     (e.g. can use `df.get_loc(column-name)` to get the column index)\n",
    "\n",
    "master_data_scaled = np.load('master_scaled_data.npy')\n",
    "master_data_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
