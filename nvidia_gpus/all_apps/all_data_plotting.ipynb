{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inst_per_warp</th>\n",
       "      <th>kernelname</th>\n",
       "      <th>branch_efficiency</th>\n",
       "      <th>warp_execution_efficiency</th>\n",
       "      <th>warp_nonpred_execution_efficiency</th>\n",
       "      <th>inst_replay_overhead</th>\n",
       "      <th>shared_load_transactions_per_request</th>\n",
       "      <th>shared_store_transactions_per_request</th>\n",
       "      <th>local_load_transactions_per_request</th>\n",
       "      <th>local_store_transactions_per_request</th>\n",
       "      <th>...</th>\n",
       "      <th>single_precision_fu_utilization</th>\n",
       "      <th>double_precision_fu_utilization</th>\n",
       "      <th>flop_hp_efficiency</th>\n",
       "      <th>flop_sp_efficiency</th>\n",
       "      <th>flop_dp_efficiency</th>\n",
       "      <th>sysmem_read_utilization</th>\n",
       "      <th>sysmem_write_utilization</th>\n",
       "      <th>architecture</th>\n",
       "      <th>application_name</th>\n",
       "      <th>input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56.00056</td>\n",
       "      <td>bpnn_adjust_weights_cuda</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.002058</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047434</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>P100</td>\n",
       "      <td>backprop</td>\n",
       "      <td>-100000_bpnn_adjust_weights_cuda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>184.00000</td>\n",
       "      <td>bpnn_layerforward_CUDA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.943953</td>\n",
       "      <td>0.761888</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.696429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004695</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>P100</td>\n",
       "      <td>backprop</td>\n",
       "      <td>-100000_bpnn_layerforward_CUDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56.00560</td>\n",
       "      <td>bpnn_adjust_weights_cuda</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.999948</td>\n",
       "      <td>0.016234</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043993</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>P100</td>\n",
       "      <td>backprop</td>\n",
       "      <td>-10000_bpnn_adjust_weights_cuda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>184.00000</td>\n",
       "      <td>bpnn_layerforward_CUDA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.943953</td>\n",
       "      <td>0.761888</td>\n",
       "      <td>0.006918</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.696429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003017</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>P100</td>\n",
       "      <td>backprop</td>\n",
       "      <td>-10000_bpnn_layerforward_CUDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56.00056</td>\n",
       "      <td>bpnn_adjust_weights_cuda</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.002492</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.048306</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>P100</td>\n",
       "      <td>backprop</td>\n",
       "      <td>-100016_bpnn_adjust_weights_cuda</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 120 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   inst_per_warp                kernelname  branch_efficiency  \\\n",
       "0       56.00056  bpnn_adjust_weights_cuda                1.0   \n",
       "1      184.00000    bpnn_layerforward_CUDA                1.0   \n",
       "2       56.00560  bpnn_adjust_weights_cuda                1.0   \n",
       "3      184.00000    bpnn_layerforward_CUDA                1.0   \n",
       "4       56.00056  bpnn_adjust_weights_cuda                1.0   \n",
       "\n",
       "   warp_execution_efficiency  warp_nonpred_execution_efficiency  \\\n",
       "0                   0.999995                           0.999994   \n",
       "1                   0.943953                           0.761888   \n",
       "2                   0.999950                           0.999948   \n",
       "3                   0.943953                           0.761888   \n",
       "4                   0.999995                           0.999994   \n",
       "\n",
       "   inst_replay_overhead  shared_load_transactions_per_request  \\\n",
       "0              0.002058                              0.000000   \n",
       "1              0.000633                              0.645833   \n",
       "2              0.016234                              0.000000   \n",
       "3              0.006918                              0.645833   \n",
       "4              0.002492                              0.000000   \n",
       "\n",
       "   shared_store_transactions_per_request  local_load_transactions_per_request  \\\n",
       "0                               0.000000                                  0.0   \n",
       "1                               0.696429                                  0.0   \n",
       "2                               0.000000                                  0.0   \n",
       "3                               0.696429                                  0.0   \n",
       "4                               0.000000                                  0.0   \n",
       "\n",
       "   local_store_transactions_per_request                ...                 \\\n",
       "0                                   0.0                ...                  \n",
       "1                                   0.0                ...                  \n",
       "2                                   0.0                ...                  \n",
       "3                                   0.0                ...                  \n",
       "4                                   0.0                ...                  \n",
       "\n",
       "   single_precision_fu_utilization  double_precision_fu_utilization  \\\n",
       "0                                2                                1   \n",
       "1                                6                                0   \n",
       "2                                3                                2   \n",
       "3                                6                                0   \n",
       "4                                2                                1   \n",
       "\n",
       "   flop_hp_efficiency  flop_sp_efficiency  flop_dp_efficiency  \\\n",
       "0                 0.0            0.000000            0.047434   \n",
       "1                 0.0            0.004695            0.000000   \n",
       "2                 0.0            0.000000            0.043993   \n",
       "3                 0.0            0.003017            0.000000   \n",
       "4                 0.0            0.000000            0.048306   \n",
       "\n",
       "   sysmem_read_utilization  sysmem_write_utilization  architecture  \\\n",
       "0                        0                         1          P100   \n",
       "1                        0                         1          P100   \n",
       "2                        0                         1          P100   \n",
       "3                        0                         1          P100   \n",
       "4                        0                         1          P100   \n",
       "\n",
       "   application_name                             input  \n",
       "0          backprop  -100000_bpnn_adjust_weights_cuda  \n",
       "1          backprop    -100000_bpnn_layerforward_CUDA  \n",
       "2          backprop   -10000_bpnn_adjust_weights_cuda  \n",
       "3          backprop     -10000_bpnn_layerforward_CUDA  \n",
       "4          backprop  -100016_bpnn_adjust_weights_cuda  \n",
       "\n",
       "[5 rows x 120 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read in master CSV file\n",
    "df = pd.read_csv('all_data.csv', index_col = 0)\n",
    "    \n",
    "# Drop columns with NaN\n",
    "df = df.dropna(axis=1,how='any')\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inst_per_warp</th>\n",
       "      <th>kernelname</th>\n",
       "      <th>branch_efficiency</th>\n",
       "      <th>warp_execution_efficiency</th>\n",
       "      <th>warp_nonpred_execution_efficiency</th>\n",
       "      <th>inst_replay_overhead</th>\n",
       "      <th>shared_load_transactions_per_request</th>\n",
       "      <th>shared_store_transactions_per_request</th>\n",
       "      <th>local_load_transactions_per_request</th>\n",
       "      <th>local_store_transactions_per_request</th>\n",
       "      <th>...</th>\n",
       "      <th>double_precision_fu_utilization</th>\n",
       "      <th>flop_hp_efficiency</th>\n",
       "      <th>flop_sp_efficiency</th>\n",
       "      <th>flop_dp_efficiency</th>\n",
       "      <th>sysmem_read_utilization</th>\n",
       "      <th>sysmem_write_utilization</th>\n",
       "      <th>architecture</th>\n",
       "      <th>application_name</th>\n",
       "      <th>input</th>\n",
       "      <th>memory_bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56.00056</td>\n",
       "      <td>bpnn_adjust_weights_cuda</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.002058</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047434</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>P100</td>\n",
       "      <td>backprop</td>\n",
       "      <td>-100000_bpnn_adjust_weights_cuda</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>184.00000</td>\n",
       "      <td>bpnn_layerforward_CUDA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.943953</td>\n",
       "      <td>0.761888</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.696429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004695</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>P100</td>\n",
       "      <td>backprop</td>\n",
       "      <td>-100000_bpnn_layerforward_CUDA</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56.00560</td>\n",
       "      <td>bpnn_adjust_weights_cuda</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.999948</td>\n",
       "      <td>0.016234</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043993</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>P100</td>\n",
       "      <td>backprop</td>\n",
       "      <td>-10000_bpnn_adjust_weights_cuda</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>184.00000</td>\n",
       "      <td>bpnn_layerforward_CUDA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.943953</td>\n",
       "      <td>0.761888</td>\n",
       "      <td>0.006918</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.696429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003017</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>P100</td>\n",
       "      <td>backprop</td>\n",
       "      <td>-10000_bpnn_layerforward_CUDA</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56.00056</td>\n",
       "      <td>bpnn_adjust_weights_cuda</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.002492</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.048306</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>P100</td>\n",
       "      <td>backprop</td>\n",
       "      <td>-100016_bpnn_adjust_weights_cuda</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   inst_per_warp                kernelname  branch_efficiency  \\\n",
       "0       56.00056  bpnn_adjust_weights_cuda                1.0   \n",
       "1      184.00000    bpnn_layerforward_CUDA                1.0   \n",
       "2       56.00560  bpnn_adjust_weights_cuda                1.0   \n",
       "3      184.00000    bpnn_layerforward_CUDA                1.0   \n",
       "4       56.00056  bpnn_adjust_weights_cuda                1.0   \n",
       "\n",
       "   warp_execution_efficiency  warp_nonpred_execution_efficiency  \\\n",
       "0                   0.999995                           0.999994   \n",
       "1                   0.943953                           0.761888   \n",
       "2                   0.999950                           0.999948   \n",
       "3                   0.943953                           0.761888   \n",
       "4                   0.999995                           0.999994   \n",
       "\n",
       "   inst_replay_overhead  shared_load_transactions_per_request  \\\n",
       "0              0.002058                              0.000000   \n",
       "1              0.000633                              0.645833   \n",
       "2              0.016234                              0.000000   \n",
       "3              0.006918                              0.645833   \n",
       "4              0.002492                              0.000000   \n",
       "\n",
       "   shared_store_transactions_per_request  local_load_transactions_per_request  \\\n",
       "0                               0.000000                                  0.0   \n",
       "1                               0.696429                                  0.0   \n",
       "2                               0.000000                                  0.0   \n",
       "3                               0.696429                                  0.0   \n",
       "4                               0.000000                                  0.0   \n",
       "\n",
       "   local_store_transactions_per_request      ...       \\\n",
       "0                                   0.0      ...        \n",
       "1                                   0.0      ...        \n",
       "2                                   0.0      ...        \n",
       "3                                   0.0      ...        \n",
       "4                                   0.0      ...        \n",
       "\n",
       "   double_precision_fu_utilization  flop_hp_efficiency  flop_sp_efficiency  \\\n",
       "0                                1                 0.0            0.000000   \n",
       "1                                0                 0.0            0.004695   \n",
       "2                                2                 0.0            0.000000   \n",
       "3                                0                 0.0            0.003017   \n",
       "4                                1                 0.0            0.000000   \n",
       "\n",
       "   flop_dp_efficiency  sysmem_read_utilization  sysmem_write_utilization  \\\n",
       "0            0.047434                        0                         1   \n",
       "1            0.000000                        0                         1   \n",
       "2            0.043993                        0                         1   \n",
       "3            0.000000                        0                         1   \n",
       "4            0.048306                        0                         1   \n",
       "\n",
       "   architecture  application_name                             input  \\\n",
       "0          P100          backprop  -100000_bpnn_adjust_weights_cuda   \n",
       "1          P100          backprop    -100000_bpnn_layerforward_CUDA   \n",
       "2          P100          backprop   -10000_bpnn_adjust_weights_cuda   \n",
       "3          P100          backprop     -10000_bpnn_layerforward_CUDA   \n",
       "4          P100          backprop  -100016_bpnn_adjust_weights_cuda   \n",
       "\n",
       "   memory_bound  \n",
       "0         False  \n",
       "1         False  \n",
       "2         False  \n",
       "3         False  \n",
       "4         False  \n",
       "\n",
       "[5 rows x 121 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define peak memory bandwidth p100 732\n",
    "peak_mem_bw = {\n",
    "    \"V100\": 898.048 * (1024*1024*1024),\n",
    "    \"P100\": 749.0 * (1024*1024*1024),\n",
    "}\n",
    "mem_bw_thresh = 0.75\n",
    "\n",
    "# Add a column specifying if the case is memory bound\n",
    "df_archs = []\n",
    "for arch in peak_mem_bw.keys():\n",
    "    df_tmp = df[df[\"architecture\"] == arch].copy()\n",
    "    new_col = (\n",
    "        df_tmp[\"dram_read_throughput\"] + df_tmp[\"dram_write_throughput\"]\n",
    "    ) / peak_mem_bw[arch]\n",
    "    new_col = new_col > mem_bw_thresh\n",
    "    df_tmp[\"memory_bound\"] = new_col\n",
    "    df_archs.append(df_tmp.copy())\n",
    "df_merged = pd.concat(df_archs).sort_index()\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20850, 121)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stream_temp = df_merged[df_merged[\"application_name\"] == 'stream']\n",
    "#stream_temp['dram_read_throughput']\n",
    "df_merged.shape\n",
    "stream_temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert bool \"memory_bound\" column to integers\n",
    "df_merged[\"memory_bound\"]= df_merged[\"memory_bound\"].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63466, 116)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we have our master dataframe (df_merged).\n",
    "# Assume the numerical data from this dataframe is used to\n",
    "# scale everything (also leave out `memory_bound` column).\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Helper funciton to return non-numerical column list\n",
    "def _get_string_cols(df_in, str_cols=None):\n",
    "    # Automatically detect non numerical columns\n",
    "    str_cols = str_cols or []\n",
    "    for col in df_in:\n",
    "        if df_in[col].dtype == 'object':\n",
    "            str_cols.append(col)\n",
    "    return str_cols\n",
    "        \n",
    "# Convert numerical columns to out training/test\n",
    "drop_cols = _get_string_cols(df_merged, ['memory_bound'])\n",
    "data_to_scale = df_merged.drop(drop_cols, axis=1).values\n",
    "scaler = StandardScaler().fit(data_to_scale)\n",
    "scaled_data_ = scaler.transform(data_to_scale)\n",
    "\n",
    "# Add column to df_merged called 'master_index'\n",
    "df_merged['master_index'] = [int(i) for i in range(len(df_merged.index))]\n",
    "\n",
    "# `scaled_data_` now has our scaled data representation.\n",
    "# The row index of the 2-D numpy array is the same as\n",
    "# the index of `df_merged`\n",
    "scaled_data_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of runs that are both on P100 and V100:  (30622, 244)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inst_per_warp_V100</th>\n",
       "      <th>kernelname_V100</th>\n",
       "      <th>branch_efficiency_V100</th>\n",
       "      <th>warp_execution_efficiency_V100</th>\n",
       "      <th>warp_nonpred_execution_efficiency_V100</th>\n",
       "      <th>inst_replay_overhead_V100</th>\n",
       "      <th>shared_load_transactions_per_request_V100</th>\n",
       "      <th>shared_store_transactions_per_request_V100</th>\n",
       "      <th>local_load_transactions_per_request_V100</th>\n",
       "      <th>local_store_transactions_per_request_V100</th>\n",
       "      <th>...</th>\n",
       "      <th>flop_hp_efficiency_P100</th>\n",
       "      <th>flop_sp_efficiency_P100</th>\n",
       "      <th>flop_dp_efficiency_P100</th>\n",
       "      <th>sysmem_read_utilization_P100</th>\n",
       "      <th>sysmem_write_utilization_P100</th>\n",
       "      <th>architecture_P100</th>\n",
       "      <th>application_name_P100</th>\n",
       "      <th>input_P100</th>\n",
       "      <th>memory_bound_P100</th>\n",
       "      <th>master_index_P100</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique_index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bpnn_adjust_weights_cuda_-100000_bpnn_adjust_weights_cuda</th>\n",
       "      <td>97.00154</td>\n",
       "      <td>bpnn_adjust_weights_cuda</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>0.999992</td>\n",
       "      <td>0.969708</td>\n",
       "      <td>0.007138</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047434</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>P100</td>\n",
       "      <td>backprop</td>\n",
       "      <td>-100000_bpnn_adjust_weights_cuda</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bpnn_layerforward_CUDA_-100000_bpnn_layerforward_CUDA</th>\n",
       "      <td>179.00000</td>\n",
       "      <td>bpnn_layerforward_CUDA</td>\n",
       "      <td>0.666666</td>\n",
       "      <td>0.690991</td>\n",
       "      <td>0.584497</td>\n",
       "      <td>0.005270</td>\n",
       "      <td>1.169071</td>\n",
       "      <td>1.005805</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004695</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>P100</td>\n",
       "      <td>backprop</td>\n",
       "      <td>-100000_bpnn_layerforward_CUDA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bpnn_adjust_weights_cuda_-10000_bpnn_adjust_weights_cuda</th>\n",
       "      <td>97.01540</td>\n",
       "      <td>bpnn_adjust_weights_cuda</td>\n",
       "      <td>0.999800</td>\n",
       "      <td>0.999920</td>\n",
       "      <td>0.969638</td>\n",
       "      <td>0.056944</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043993</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>P100</td>\n",
       "      <td>backprop</td>\n",
       "      <td>-10000_bpnn_adjust_weights_cuda</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bpnn_layerforward_CUDA_-10000_bpnn_layerforward_CUDA</th>\n",
       "      <td>179.00000</td>\n",
       "      <td>bpnn_layerforward_CUDA</td>\n",
       "      <td>0.666666</td>\n",
       "      <td>0.690991</td>\n",
       "      <td>0.584497</td>\n",
       "      <td>0.027619</td>\n",
       "      <td>1.083897</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003017</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>P100</td>\n",
       "      <td>backprop</td>\n",
       "      <td>-10000_bpnn_layerforward_CUDA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bpnn_adjust_weights_cuda_-100016_bpnn_adjust_weights_cuda</th>\n",
       "      <td>97.00154</td>\n",
       "      <td>bpnn_adjust_weights_cuda</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>0.999992</td>\n",
       "      <td>0.969708</td>\n",
       "      <td>0.004211</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.048306</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>P100</td>\n",
       "      <td>backprop</td>\n",
       "      <td>-100016_bpnn_adjust_weights_cuda</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 244 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    inst_per_warp_V100  \\\n",
       "unique_index                                                             \n",
       "bpnn_adjust_weights_cuda_-100000_bpnn_adjust_we...            97.00154   \n",
       "bpnn_layerforward_CUDA_-100000_bpnn_layerforwar...           179.00000   \n",
       "bpnn_adjust_weights_cuda_-10000_bpnn_adjust_wei...            97.01540   \n",
       "bpnn_layerforward_CUDA_-10000_bpnn_layerforward...           179.00000   \n",
       "bpnn_adjust_weights_cuda_-100016_bpnn_adjust_we...            97.00154   \n",
       "\n",
       "                                                             kernelname_V100  \\\n",
       "unique_index                                                                   \n",
       "bpnn_adjust_weights_cuda_-100000_bpnn_adjust_we...  bpnn_adjust_weights_cuda   \n",
       "bpnn_layerforward_CUDA_-100000_bpnn_layerforwar...    bpnn_layerforward_CUDA   \n",
       "bpnn_adjust_weights_cuda_-10000_bpnn_adjust_wei...  bpnn_adjust_weights_cuda   \n",
       "bpnn_layerforward_CUDA_-10000_bpnn_layerforward...    bpnn_layerforward_CUDA   \n",
       "bpnn_adjust_weights_cuda_-100016_bpnn_adjust_we...  bpnn_adjust_weights_cuda   \n",
       "\n",
       "                                                    branch_efficiency_V100  \\\n",
       "unique_index                                                                 \n",
       "bpnn_adjust_weights_cuda_-100000_bpnn_adjust_we...                0.999980   \n",
       "bpnn_layerforward_CUDA_-100000_bpnn_layerforwar...                0.666666   \n",
       "bpnn_adjust_weights_cuda_-10000_bpnn_adjust_wei...                0.999800   \n",
       "bpnn_layerforward_CUDA_-10000_bpnn_layerforward...                0.666666   \n",
       "bpnn_adjust_weights_cuda_-100016_bpnn_adjust_we...                0.999980   \n",
       "\n",
       "                                                    warp_execution_efficiency_V100  \\\n",
       "unique_index                                                                         \n",
       "bpnn_adjust_weights_cuda_-100000_bpnn_adjust_we...                        0.999992   \n",
       "bpnn_layerforward_CUDA_-100000_bpnn_layerforwar...                        0.690991   \n",
       "bpnn_adjust_weights_cuda_-10000_bpnn_adjust_wei...                        0.999920   \n",
       "bpnn_layerforward_CUDA_-10000_bpnn_layerforward...                        0.690991   \n",
       "bpnn_adjust_weights_cuda_-100016_bpnn_adjust_we...                        0.999992   \n",
       "\n",
       "                                                    warp_nonpred_execution_efficiency_V100  \\\n",
       "unique_index                                                                                 \n",
       "bpnn_adjust_weights_cuda_-100000_bpnn_adjust_we...                                0.969708   \n",
       "bpnn_layerforward_CUDA_-100000_bpnn_layerforwar...                                0.584497   \n",
       "bpnn_adjust_weights_cuda_-10000_bpnn_adjust_wei...                                0.969638   \n",
       "bpnn_layerforward_CUDA_-10000_bpnn_layerforward...                                0.584497   \n",
       "bpnn_adjust_weights_cuda_-100016_bpnn_adjust_we...                                0.969708   \n",
       "\n",
       "                                                    inst_replay_overhead_V100  \\\n",
       "unique_index                                                                    \n",
       "bpnn_adjust_weights_cuda_-100000_bpnn_adjust_we...                   0.007138   \n",
       "bpnn_layerforward_CUDA_-100000_bpnn_layerforwar...                   0.005270   \n",
       "bpnn_adjust_weights_cuda_-10000_bpnn_adjust_wei...                   0.056944   \n",
       "bpnn_layerforward_CUDA_-10000_bpnn_layerforward...                   0.027619   \n",
       "bpnn_adjust_weights_cuda_-100016_bpnn_adjust_we...                   0.004211   \n",
       "\n",
       "                                                    shared_load_transactions_per_request_V100  \\\n",
       "unique_index                                                                                    \n",
       "bpnn_adjust_weights_cuda_-100000_bpnn_adjust_we...                                   0.000000   \n",
       "bpnn_layerforward_CUDA_-100000_bpnn_layerforwar...                                   1.169071   \n",
       "bpnn_adjust_weights_cuda_-10000_bpnn_adjust_wei...                                   0.000000   \n",
       "bpnn_layerforward_CUDA_-10000_bpnn_layerforward...                                   1.083897   \n",
       "bpnn_adjust_weights_cuda_-100016_bpnn_adjust_we...                                   0.000000   \n",
       "\n",
       "                                                    shared_store_transactions_per_request_V100  \\\n",
       "unique_index                                                                                     \n",
       "bpnn_adjust_weights_cuda_-100000_bpnn_adjust_we...                                    0.000000   \n",
       "bpnn_layerforward_CUDA_-100000_bpnn_layerforwar...                                    1.005805   \n",
       "bpnn_adjust_weights_cuda_-10000_bpnn_adjust_wei...                                    0.000000   \n",
       "bpnn_layerforward_CUDA_-10000_bpnn_layerforward...                                    1.000000   \n",
       "bpnn_adjust_weights_cuda_-100016_bpnn_adjust_we...                                    0.000000   \n",
       "\n",
       "                                                    local_load_transactions_per_request_V100  \\\n",
       "unique_index                                                                                   \n",
       "bpnn_adjust_weights_cuda_-100000_bpnn_adjust_we...                                       0.0   \n",
       "bpnn_layerforward_CUDA_-100000_bpnn_layerforwar...                                       0.0   \n",
       "bpnn_adjust_weights_cuda_-10000_bpnn_adjust_wei...                                       0.0   \n",
       "bpnn_layerforward_CUDA_-10000_bpnn_layerforward...                                       0.0   \n",
       "bpnn_adjust_weights_cuda_-100016_bpnn_adjust_we...                                       0.0   \n",
       "\n",
       "                                                    local_store_transactions_per_request_V100  \\\n",
       "unique_index                                                                                    \n",
       "bpnn_adjust_weights_cuda_-100000_bpnn_adjust_we...                                        0.0   \n",
       "bpnn_layerforward_CUDA_-100000_bpnn_layerforwar...                                        0.0   \n",
       "bpnn_adjust_weights_cuda_-10000_bpnn_adjust_wei...                                        0.0   \n",
       "bpnn_layerforward_CUDA_-10000_bpnn_layerforward...                                        0.0   \n",
       "bpnn_adjust_weights_cuda_-100016_bpnn_adjust_we...                                        0.0   \n",
       "\n",
       "                                                          ...          \\\n",
       "unique_index                                              ...           \n",
       "bpnn_adjust_weights_cuda_-100000_bpnn_adjust_we...        ...           \n",
       "bpnn_layerforward_CUDA_-100000_bpnn_layerforwar...        ...           \n",
       "bpnn_adjust_weights_cuda_-10000_bpnn_adjust_wei...        ...           \n",
       "bpnn_layerforward_CUDA_-10000_bpnn_layerforward...        ...           \n",
       "bpnn_adjust_weights_cuda_-100016_bpnn_adjust_we...        ...           \n",
       "\n",
       "                                                    flop_hp_efficiency_P100  \\\n",
       "unique_index                                                                  \n",
       "bpnn_adjust_weights_cuda_-100000_bpnn_adjust_we...                      0.0   \n",
       "bpnn_layerforward_CUDA_-100000_bpnn_layerforwar...                      0.0   \n",
       "bpnn_adjust_weights_cuda_-10000_bpnn_adjust_wei...                      0.0   \n",
       "bpnn_layerforward_CUDA_-10000_bpnn_layerforward...                      0.0   \n",
       "bpnn_adjust_weights_cuda_-100016_bpnn_adjust_we...                      0.0   \n",
       "\n",
       "                                                    flop_sp_efficiency_P100  \\\n",
       "unique_index                                                                  \n",
       "bpnn_adjust_weights_cuda_-100000_bpnn_adjust_we...                 0.000000   \n",
       "bpnn_layerforward_CUDA_-100000_bpnn_layerforwar...                 0.004695   \n",
       "bpnn_adjust_weights_cuda_-10000_bpnn_adjust_wei...                 0.000000   \n",
       "bpnn_layerforward_CUDA_-10000_bpnn_layerforward...                 0.003017   \n",
       "bpnn_adjust_weights_cuda_-100016_bpnn_adjust_we...                 0.000000   \n",
       "\n",
       "                                                    flop_dp_efficiency_P100  \\\n",
       "unique_index                                                                  \n",
       "bpnn_adjust_weights_cuda_-100000_bpnn_adjust_we...                 0.047434   \n",
       "bpnn_layerforward_CUDA_-100000_bpnn_layerforwar...                 0.000000   \n",
       "bpnn_adjust_weights_cuda_-10000_bpnn_adjust_wei...                 0.043993   \n",
       "bpnn_layerforward_CUDA_-10000_bpnn_layerforward...                 0.000000   \n",
       "bpnn_adjust_weights_cuda_-100016_bpnn_adjust_we...                 0.048306   \n",
       "\n",
       "                                                    sysmem_read_utilization_P100  \\\n",
       "unique_index                                                                       \n",
       "bpnn_adjust_weights_cuda_-100000_bpnn_adjust_we...                           0.0   \n",
       "bpnn_layerforward_CUDA_-100000_bpnn_layerforwar...                           0.0   \n",
       "bpnn_adjust_weights_cuda_-10000_bpnn_adjust_wei...                           0.0   \n",
       "bpnn_layerforward_CUDA_-10000_bpnn_layerforward...                           0.0   \n",
       "bpnn_adjust_weights_cuda_-100016_bpnn_adjust_we...                           0.0   \n",
       "\n",
       "                                                    sysmem_write_utilization_P100  \\\n",
       "unique_index                                                                        \n",
       "bpnn_adjust_weights_cuda_-100000_bpnn_adjust_we...                            1.0   \n",
       "bpnn_layerforward_CUDA_-100000_bpnn_layerforwar...                            1.0   \n",
       "bpnn_adjust_weights_cuda_-10000_bpnn_adjust_wei...                            1.0   \n",
       "bpnn_layerforward_CUDA_-10000_bpnn_layerforward...                            1.0   \n",
       "bpnn_adjust_weights_cuda_-100016_bpnn_adjust_we...                            1.0   \n",
       "\n",
       "                                                    architecture_P100  \\\n",
       "unique_index                                                            \n",
       "bpnn_adjust_weights_cuda_-100000_bpnn_adjust_we...               P100   \n",
       "bpnn_layerforward_CUDA_-100000_bpnn_layerforwar...               P100   \n",
       "bpnn_adjust_weights_cuda_-10000_bpnn_adjust_wei...               P100   \n",
       "bpnn_layerforward_CUDA_-10000_bpnn_layerforward...               P100   \n",
       "bpnn_adjust_weights_cuda_-100016_bpnn_adjust_we...               P100   \n",
       "\n",
       "                                                    application_name_P100  \\\n",
       "unique_index                                                                \n",
       "bpnn_adjust_weights_cuda_-100000_bpnn_adjust_we...               backprop   \n",
       "bpnn_layerforward_CUDA_-100000_bpnn_layerforwar...               backprop   \n",
       "bpnn_adjust_weights_cuda_-10000_bpnn_adjust_wei...               backprop   \n",
       "bpnn_layerforward_CUDA_-10000_bpnn_layerforward...               backprop   \n",
       "bpnn_adjust_weights_cuda_-100016_bpnn_adjust_we...               backprop   \n",
       "\n",
       "                                                                          input_P100  \\\n",
       "unique_index                                                                           \n",
       "bpnn_adjust_weights_cuda_-100000_bpnn_adjust_we...  -100000_bpnn_adjust_weights_cuda   \n",
       "bpnn_layerforward_CUDA_-100000_bpnn_layerforwar...    -100000_bpnn_layerforward_CUDA   \n",
       "bpnn_adjust_weights_cuda_-10000_bpnn_adjust_wei...   -10000_bpnn_adjust_weights_cuda   \n",
       "bpnn_layerforward_CUDA_-10000_bpnn_layerforward...     -10000_bpnn_layerforward_CUDA   \n",
       "bpnn_adjust_weights_cuda_-100016_bpnn_adjust_we...  -100016_bpnn_adjust_weights_cuda   \n",
       "\n",
       "                                                    memory_bound_P100  \\\n",
       "unique_index                                                            \n",
       "bpnn_adjust_weights_cuda_-100000_bpnn_adjust_we...                0.0   \n",
       "bpnn_layerforward_CUDA_-100000_bpnn_layerforwar...                0.0   \n",
       "bpnn_adjust_weights_cuda_-10000_bpnn_adjust_wei...                0.0   \n",
       "bpnn_layerforward_CUDA_-10000_bpnn_layerforward...                0.0   \n",
       "bpnn_adjust_weights_cuda_-100016_bpnn_adjust_we...                0.0   \n",
       "\n",
       "                                                    master_index_P100  \n",
       "unique_index                                                           \n",
       "bpnn_adjust_weights_cuda_-100000_bpnn_adjust_we...                0.0  \n",
       "bpnn_layerforward_CUDA_-100000_bpnn_layerforwar...                1.0  \n",
       "bpnn_adjust_weights_cuda_-10000_bpnn_adjust_wei...                2.0  \n",
       "bpnn_layerforward_CUDA_-10000_bpnn_layerforward...                3.0  \n",
       "bpnn_adjust_weights_cuda_-100016_bpnn_adjust_we...                4.0  \n",
       "\n",
       "[5 rows x 244 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets create a dataframe (df_joined) with each row\n",
    "# corresponding to a specific type of run.\n",
    "# The V100 and P100 metrics are included in the same row,\n",
    "# with `_V100` appended to the metric label for V100, etc.\n",
    "# This means we have 2x the number of metrics for each row.\n",
    "base = 'V100'\n",
    "other = 'P100'\n",
    "\n",
    "df_all = df_merged.copy()\n",
    "unique_col = [] #column that has matches of kernels run on both architectures\n",
    "for k, i in zip(df_all['kernelname'].values, df_all['input'].values):\n",
    "    unique_col.append(k+'_'+i)\n",
    "df_all['unique_index'] = unique_col\n",
    "df_all.set_index('unique_index', inplace=True)\n",
    "\n",
    "# Create 'base' and 'other' dataframes for join\n",
    "df_b = df_all[df_all['architecture'] == base].copy()\n",
    "df_o = df_all[df_all['architecture'] == other].copy()\n",
    "\n",
    "# Final join operation, and drop rows with NaN elements\n",
    "df_joined = df_b.join(df_o, lsuffix='_'+base, rsuffix='_'+other)\n",
    "df_joined = df_joined.dropna(axis=0,how='any')\n",
    "print(\"Number of runs that are both on P100 and V100: \", df_joined.shape)\n",
    "df_joined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We know know how to map dataframe columns to scaled-data columns\n",
    "# However, we need to map column indices as well...\n",
    "# Drop columns from df_merged to get a dataframe for\n",
    "# determining the index of columns\n",
    "drop_cols = _get_string_cols(df_merged, ['memory_bound','master_index'])\n",
    "df_col_ref = df_merged.drop(drop_cols, axis=1).copy()\n",
    "\n",
    "# We are assuming here that the columns of `df_col_ref`\n",
    "# are ordered in the same way as `scaled_data_`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory Bound cross over analysis\n",
    "Graph below shows the applications that go to being compute bound on the V100. Shoes that these apps have a significant \n",
    "increase in write and read throughput "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_basis = ['dram_read_throughput', 'dram_write_throughput']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "colors = (\"black\", \"red\", \"green\", \"blue\")\n",
    "groups = ('backprop', 'hybridsort', 'kmeans', 'srad', 'stream')\n",
    "\n",
    "df_plot = df_joined[df_joined['memory_bound_V100'] == 1].copy()\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(15,6))\n",
    "\n",
    "for iax, ax in enumerate(axs):\n",
    "    for arch in ['_V100', '_P100']:\n",
    "        for color, group in zip(colors, groups):\n",
    "\n",
    "            dft = df_plot[df_plot['application_name'+arch] == group]\n",
    "\n",
    "            if iax == 0:\n",
    "                #import pdb; pdb.set_trace()\n",
    "                ax.set_title('Scaled Data')\n",
    "                indices = [int(i) for i in dft['master_index'+arch].values]\n",
    "                x_col_ind = df_col_ref.columns.get_loc(metric_basis[0])\n",
    "                y_col_ind = df_col_ref.columns.get_loc(metric_basis[1])\n",
    "                x = scaled_data_[indices,x_col_ind]\n",
    "                y = scaled_data_[indices,y_col_ind]\n",
    "                ax.set_xlabel(metric_basis[0]+' [Scaled]')\n",
    "                ax.set_ylabel(metric_basis[1]+' [Scaled]')\n",
    "            else:\n",
    "                ax.set_title('Real Data')\n",
    "                x = dft[metric_basis[0]+arch].values\n",
    "                y = dft[metric_basis[1]+arch].values\n",
    "                ax.set_xlabel(metric_basis[0])\n",
    "                ax.set_ylabel(metric_basis[1])\n",
    "\n",
    "            if arch == '_V100':\n",
    "                ax.scatter(x, y, alpha=0.8, c=color, edgecolors='none', s=20, marker='o', label=group)\n",
    "            else:\n",
    "                ax.scatter(x, y, alpha=0.8, c='none', edgecolors=color, s=60, marker='s')\n",
    "                \n",
    "\n",
    "plt.suptitle('Memory-bound Applications on V100\\n(Squares == P100 Data)')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1029 22:25:09.738579 4611536320 deprecation.py:506] From /Users/yzamora/miniconda3/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W1029 22:25:09.739421 4611536320 deprecation.py:506] From /Users/yzamora/miniconda3/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W1029 22:25:09.740879 4611536320 deprecation.py:506] From /Users/yzamora/miniconda3/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "# Now, lets see how predictions for V100 (given P100) compare...\n",
    " \n",
    "#from deephyper.search.nas.model.train_utils import selectMetric\n",
    "import sys\n",
    "sys.path.append('/Users/yzamora/deephyper/deephyper/search/nas/model')\n",
    "from train_utils import selectMetric\n",
    "import tensorflow as tf\n",
    "\n",
    "\"\"\"\n",
    "def weighted_mse(loss_weight):\n",
    "    def loss(y_true, y_pred):\n",
    "        loss = K.mean(K.square(y_true - y_pred)*loss_weight)\n",
    "        return loss\n",
    "    return loss\n",
    "\n",
    "loss_weight = np.ones(116)\n",
    "loss_weight[96] = 1#17\n",
    "loss_weight[33] = 100#15 dram_read\n",
    "loss_weight[34] = 100#14 dram_Write\n",
    "loss_weight[105] = 1#13\n",
    "loss_weight[106] = 1#10\n",
    "#model = load_model('bslh_DL_wbias.h5',custom_objects={'loss': weighted_mse(loss_weight)}) # first attempt\n",
    "#model = load_model('20perdata_dram_bias.h5',custom_objects={'loss':weighted_mse(loss_weight)})\n",
    "model = load_model('12deeper-noappweight_membounds2_dram_kmeans_zerobias.h5',custom_objects={'loss':weighted_mse(loss_weight)})\n",
    "\"\"\"\n",
    "\n",
    "##testing deephyper returned model\n",
    "model_path = '/Users/yzamora/power/nvidia_gpus/all_apps/deephyper_models/best_model_18_per20.h5' \n",
    "model = tf.keras.models.load_model(model_path,\n",
    "    custom_objects={\n",
    "        'r2': selectMetric('r2')\n",
    "    }\n",
    "                                  )\n",
    "\n",
    "#model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = df_joined[df_joined['memory_bound_V100'] == 1].copy()\n",
    "\n",
    "\n",
    "## how to save points that were predicted to be memory bound, use that train \n",
    "## new deep learning model with less data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "colors = (\"black\", \"red\", \"green\", \"blue\" ,\"pink\")\n",
    "groups = ('backprop', 'hybridsort', 'kmeans', 'srad')\n",
    "\n",
    "##df_plot = df_joined[df_joined['memory_bound_V100'] == 1].copy()\n",
    "df_plot = df_joined.copy()\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(15,10))\n",
    "\n",
    "for color, group in zip(colors, groups):\n",
    "    df_predict = df_plot[df_plot['application_name_V100'] == group].copy()\n",
    "    indices_to_predict = [int(i) for i in df_predict['master_index_P100'].values]\n",
    "    prediction = model.predict(scaled_data_[indices_to_predict])\n",
    "    \n",
    "    try:\n",
    "        print(prediction.max())\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Print measured V100 metrics\n",
    "    indices = [int(i) for i in df_predict['master_index_V100'].values]\n",
    "    x_col_ind = df_col_ref.columns.get_loc(metric_basis[0])\n",
    "    y_col_ind = df_col_ref.columns.get_loc(metric_basis[1])\n",
    "    x = scaled_data_[indices,x_col_ind]\n",
    "    y = scaled_data_[indices,y_col_ind]\n",
    "    ax.scatter(x, y, alpha=0.8, c=color, edgecolors='none', s=20, marker='o', label=group)\n",
    "\n",
    "    # Print measured P100 metrics\n",
    "    indices = [int(i) for i in df_predict['master_index_P100'].values]\n",
    "    x_col_ind = df_col_ref.columns.get_loc(metric_basis[0])\n",
    "    y_col_ind = df_col_ref.columns.get_loc(metric_basis[1])\n",
    "    x = scaled_data_[indices,x_col_ind]\n",
    "    y = scaled_data_[indices,y_col_ind]\n",
    "    ax.scatter(x, y, alpha=0.8, c='none', edgecolors=color, s=100, marker='s')\n",
    "    \n",
    "    # Print V100 predictions (from measured P100 metrics)\n",
    "    if indices_to_predict: # Need to check that there are predictions to plot here...\n",
    "        x_col_ind = df_col_ref.columns.get_loc(metric_basis[0])\n",
    "        y_col_ind = df_col_ref.columns.get_loc(metric_basis[1]) \n",
    "        x = prediction[:,x_col_ind]\n",
    "        y = prediction[:,y_col_ind]   \n",
    "        ax.scatter(x, y, alpha=0.8, c='none', edgecolors=color, s=400, marker='^')\n",
    "    \n",
    "    \n",
    "plt.xlabel(metric_basis[0]+' [Scaled]')\n",
    "plt.ylabel(metric_basis[1]+' [Scaled]')\n",
    "plt.title('All data on V100\\n(Squares == P100 Data, Triangles == Predicted V100 Data)')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## !!!!!!!! TRY VIOLIN PLOT !!!!!1\n",
    "##pred_dram = prediction[:,33]/ prediction[:,34]\n",
    "##true_dram = scaled_data_[indices,33]/scaled_data_[indices,34]\n",
    "##print (\"predicted ratio\", pred_dram)\n",
    "##print(\"true ratio\", true_dram)\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(15,10))\n",
    "## looking at scaled values\n",
    "colors = (\"black\", \"red\", \"green\", \"blue\" ,\"pink\")\n",
    "groups = ('backprop', 'hybridsort', 'kmeans', 'srad')\n",
    "\n",
    "for color, group in zip(colors, groups):\n",
    "    df_predict = df_plot[df_plot['application_name_V100'] == group].copy()\n",
    "    indices_to_predict = [int(i) for i in df_predict['master_index_P100'].values]\n",
    "    prediction = model.predict(scaled_data_[indices_to_predict])\n",
    "    #import pdb; pdb.set_trace()\n",
    "    try:\n",
    "        print(prediction.max())\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Print measured V100 metrics\n",
    "    indices = [int(i) for i in df_predict['master_index_V100'].values]\n",
    "    x_col_ind = df_col_ref.columns.get_loc(metric_basis[0])\n",
    "    y_col_ind = df_col_ref.columns.get_loc(metric_basis[1])\n",
    "    x = scaled_data_[indices,33]\n",
    "    y = scaled_data_[indices,32]\n",
    "    dram_total = x + y\n",
    "    ax.scatter([group for v in dram_total], dram_total, alpha=0.8, c=color, edgecolors='none', s=20, marker='o', label=group+'_V100')\n",
    "\n",
    "    # Print measured P100 metrics\n",
    "    indices = [int(i) for i in df_predict['master_index_P100'].values]\n",
    "    x_col_ind = df_col_ref.columns.get_loc(metric_basis[0])\n",
    "    y_col_ind = df_col_ref.columns.get_loc(metric_basis[1])\n",
    "    x = scaled_data_[indices,33]\n",
    "    y = scaled_data_[indices,34]\n",
    "    dram_total = x + y\n",
    "    ax.scatter([group for v in dram_total], dram_total, alpha=0.8, c='none', edgecolors=color, s=100, marker='s', label=group+'_P100')\n",
    "\n",
    "    #print(\"Ratio for true P100 metric group\", group, x/y)\n",
    "    \n",
    "    # Print V100 predictions (from measured P100 metrics)\n",
    "    if indices_to_predict: # Need to check that there are predictions to plot here...\n",
    "        x_col_ind = df_col_ref.columns.get_loc(metric_basis[0])\n",
    "        y_col_ind = df_col_ref.columns.get_loc(metric_basis[1]) \n",
    "        x = prediction[:,33]\n",
    "        y = prediction[:,34]\n",
    "        dram_total = x + y\n",
    "        ax.scatter([group for v in dram_total], dram_total, alpha=0.8, c='none', edgecolors=color, s=400, marker='^', label=group+'_V100_Predicted')\n",
    "\n",
    "        #print(\"Ratio for predicted V100 metric group\", group, x/y)\n",
    "        \n",
    "plt.ylabel(\"dram_write + dram_read throughput\")\n",
    "plt.xlabel('Applications')\n",
    "plt.title('All data results\\n(Squares == P100 Data, Triangles == Predicted V100 Data)')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#are the ratios between dram read and write kept the same for true data and predicted data - \n",
    "#compare ratios, are they the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## look at histogram distribution chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = [1,2,3,4]\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot\n",
    "import seaborn \n",
    "for color, group in zip(colors, groups):\n",
    "    df_predict = df_plot[df_plot['application_name_V100'] == group].copy()\n",
    "    indices_to_predict = [int(i) for i in df_predict['master_index_P100'].values]\n",
    "    prediction = model.predict(scaled_data_[indices_to_predict])\n",
    "    #import pdb; pdb.set_trace()\n",
    "    try:\n",
    "        print(prediction.max())\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Print measured V100 metrics\n",
    "    indices = [int(i) for i in df_predict['master_index_V100'].values]\n",
    "    x_col_ind = df_col_ref.columns.get_loc(metric_basis[0])\n",
    "    y_col_ind = df_col_ref.columns.get_loc(metric_basis[1])\n",
    "    x = scaled_data_[indices,33]\n",
    "    y = scaled_data_[indices,32]\n",
    "    dram_total = x + y\n",
    "    fig, ax = pyplot.subplots(figsize =(9, 7)) \n",
    "    plt.title(group)\n",
    "    sns.violinplot(ax=ax,y=dram_total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print V100 predictions (from measured P100 metrics)\n",
    "for color, group in zip(colors, groups):\n",
    "    if indices_to_predict: # Need to check that there are predictions to plot here...\n",
    "        df_predict = df_plot[df_plot['application_name_V100'] == group].copy()\n",
    "        indices_to_predict = [int(i) for i in df_predict['master_index_P100'].values]\n",
    "        prediction = model.predict(scaled_data_[indices_to_predict])\n",
    "        x_col_ind = df_col_ref.columns.get_loc(metric_basis[0])\n",
    "        y_col_ind = df_col_ref.columns.get_loc(metric_basis[1]) \n",
    "        x = prediction[:,33]\n",
    "        y = prediction[:,34]\n",
    "        dram_total = x + y\n",
    "        fig, ax = pyplot.subplots(figsize =(9, 7))\n",
    "        plt.title(group)\n",
    "        sns.violinplot(ax=ax,y=dram_total,color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot\n",
    "import seaborn \n",
    "#fig, ax = pyplot.subplots(figsize =(9, 7))\n",
    "\n",
    "for color, group in zip(colors, groups):\n",
    "    \n",
    "    fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(15,10))\n",
    "    \n",
    "    \n",
    "    df_predict = df_plot[df_plot['application_name_V100'] == group].copy()\n",
    "    indices_to_predict = [int(i) for i in df_predict['master_index_P100'].values]\n",
    "    prediction = model.predict(scaled_data_[indices_to_predict])\n",
    "    #import pdb; pdb.set_trace()\n",
    "    try:\n",
    "        print(prediction.max())\n",
    "    except:\n",
    "        pass\n",
    "    # Print measured P100 metrics\n",
    "    indices = [int(i) for i in df_predict['master_index_P100'].values]\n",
    "    x_col_ind = df_col_ref.columns.get_loc(metric_basis[0])\n",
    "    y_col_ind = df_col_ref.columns.get_loc(metric_basis[1])\n",
    "    x = scaled_data_[indices,33]\n",
    "    y = scaled_data_[indices,34]\n",
    "    dram_total = x + y\n",
    "    ax[0].set_title(\"Measured P100 metrics\")\n",
    "    sns.violinplot(ax=ax[0],y=dram_total,color='b')\n",
    "    \n",
    "    # Print measured V100 metrics\n",
    "    indices = [int(i) for i in df_predict['master_index_V100'].values]\n",
    "    x_col_ind = df_col_ref.columns.get_loc(metric_basis[0])\n",
    "    y_col_ind = df_col_ref.columns.get_loc(metric_basis[1])\n",
    "    x = scaled_data_[indices,33]\n",
    "    y = scaled_data_[indices,32]\n",
    "    dram_total = x + y\n",
    "    #fig, ax = pyplot.subplots(figsize =(9, 7)) \n",
    "    ax[1].set_title(\"Measured V100 metrics\")\n",
    "    sns.violinplot(ax=ax[1],y=dram_total,color='g')\n",
    "    \n",
    "    # Print V100 predictions (from measured P100 metrics)\n",
    "    if indices_to_predict: # Need to check that there are predictions to plot here...\n",
    "        x_col_ind = df_col_ref.columns.get_loc(metric_basis[0])\n",
    "        y_col_ind = df_col_ref.columns.get_loc(metric_basis[1]) \n",
    "        x = prediction[:,33]\n",
    "        y = prediction[:,34]\n",
    "        dram_total = x + y\n",
    "        #fig, ax = pyplot.subplots(figsize =(9, 7))\n",
    "        ax[2].set_title(\"V100 Predictions\")\n",
    "        sns.violinplot(ax=ax[2],y=dram_total,color='r')\n",
    "    \n",
    "plt.ylabel(\"dram_write + dram_read throughput\")\n",
    "plt.xlabel('Applications')\n",
    "plt.title('All data results')\n",
    "#plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SIDE BY SIDE\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot\n",
    "import seaborn \n",
    "#fig, ax = pyplot.subplots(figsize =(9, 7))\n",
    "\n",
    "for color, group in zip(colors, groups):\n",
    "    \n",
    "    #fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(15,10))\n",
    "    fig, ax = plt.subplots(figsize=(15,10))\n",
    "    \n",
    "    myplot = {}\n",
    "    \n",
    "    df_predict = df_plot[df_plot['application_name_V100'] == group].copy()\n",
    "    indices_to_predict = [int(i) for i in df_predict['master_index_P100'].values]\n",
    "    prediction = model.predict(scaled_data_[indices_to_predict])\n",
    "    #import pdb; pdb.set_trace()\n",
    "    try:\n",
    "        print(prediction.max())\n",
    "    except:\n",
    "        pass\n",
    "    # Print measured P100 metrics\n",
    "    indices = [int(i) for i in df_predict['master_index_P100'].values]\n",
    "    x_col_ind = df_col_ref.columns.get_loc(metric_basis[0])\n",
    "    y_col_ind = df_col_ref.columns.get_loc(metric_basis[1])\n",
    "    x = scaled_data_[indices,33]\n",
    "    y = scaled_data_[indices,34]\n",
    "    dram_total = x + y\n",
    "    ax.set_title(\"Measured P100 metrics\")\n",
    "    #sns.violinplot(ax=ax[0],y=dram_total,color='b')\n",
    "    myplot[\"Metrics\"] = dram_total.tolist()\n",
    "    myplot[\"Type\"] = [\"Real\" for i in range(len(dram_total.tolist()))]\n",
    "    myplot[\"Architecture\"] = [\"P100\" for i in range(len(dram_total.tolist()))]\n",
    "    \n",
    "    # Print measured V100 metrics\n",
    "    indices = [int(i) for i in df_predict['master_index_V100'].values]\n",
    "    x_col_ind = df_col_ref.columns.get_loc(metric_basis[0])\n",
    "    y_col_ind = df_col_ref.columns.get_loc(metric_basis[1])\n",
    "    x = scaled_data_[indices,33]\n",
    "    y = scaled_data_[indices,32]\n",
    "    dram_total = x + y\n",
    "    #fig, ax = pyplot.subplots(figsize =(9, 7)) \n",
    "    ax.set_title(\"Measured V100 metrics\")\n",
    "    #sns.violinplot(ax=ax[1],y=dram_total,color='g')\n",
    "    myplot[\"Metrics\"] += dram_total.tolist()\n",
    "    myplot[\"Type\"] += [\"Real\" for i in range(len(dram_total.tolist()))]\n",
    "    myplot[\"Architecture\"] += [\"V100\" for i in range(len(dram_total.tolist()))]\n",
    "    \n",
    "    # Print V100 predictions (from measured P100 metrics)\n",
    "    if indices_to_predict: # Need to check that there are predictions to plot here...\n",
    "        x_col_ind = df_col_ref.columns.get_loc(metric_basis[0])\n",
    "        y_col_ind = df_col_ref.columns.get_loc(metric_basis[1]) \n",
    "        x = prediction[:,33]\n",
    "        y = prediction[:,34]\n",
    "        dram_total = x + y\n",
    "        #fig, ax = pyplot.subplots(figsize =(9, 7))\n",
    "        #ax[2].set_title(\"V100 Predictions\")\n",
    "        #sns.violinplot(ax=ax[2],y=dram_total,color='r')\n",
    "        myplot[\"Metrics\"] += dram_total.tolist()\n",
    "        myplot[\"Type\"] += [\"Predicted\" for i in range(len(dram_total.tolist()))]\n",
    "        myplot[\"Architecture\"] += [\"V100\" for i in range(len(dram_total.tolist()))]\n",
    "        myplot = pd.DataFrame(myplot)\n",
    "        ax = sns.violinplot(x=\"Architecture\", y=\"Metrics\", data=pd.DataFrame(myplot), hue=\"Type\", palette=\"muted\", split=True)\n",
    "    \n",
    "plt.ylabel(\"dram_write + dram_read throughput\")\n",
    "plt.xlabel('Applications')\n",
    "plt.title('All data results')\n",
    "#plt.legend(loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "print(myplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = (\"black\", \"red\", \"green\", \"blue\")\n",
    "groups = ('backprop', 'hybridsort', 'kmeans', 'srad','stream')\n",
    "\n",
    "ipoint = 10  # Start with this case\n",
    "npoints = 1  # Plot this many cases (must be small to make visual sense)\n",
    "\n",
    "df_plot = df_joined[df_joined['memory_bound_V100'] == 0].copy()\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(15,10))\n",
    "\n",
    "axs = [axes[0][0],axes[0][1],axes[1][0],axes[1][1]]\n",
    "\n",
    "for ix, ax in enumerate(axs):\n",
    "    ipoint += ix*npoints\n",
    "    for color, group in zip(colors, groups):\n",
    "        df_predict = df_plot[df_plot['application_name_V100'] == group].copy()\n",
    "        indices_to_predict = [int(i) for i in df_predict['master_index_P100'].values]\n",
    "        prediction = model.predict(scaled_data_[indices_to_predict])\n",
    "\n",
    "        # Print measured V100 metrics\n",
    "        indices = [int(i) for i in df_predict['master_index_V100'].values]\n",
    "        x_col_ind = df_col_ref.columns.get_loc(metric_basis[0])\n",
    "        y_col_ind = df_col_ref.columns.get_loc(metric_basis[1])\n",
    "        x = scaled_data_[indices,x_col_ind][ipoint:ipoint+npoints]\n",
    "        y = scaled_data_[indices,y_col_ind][ipoint:ipoint+npoints]\n",
    "        ax.scatter(x, y, alpha=0.8, c=color, edgecolors='none', s=20, marker='o', label=group)\n",
    "\n",
    "        # Print measured P100 metrics\n",
    "        indices = [int(i) for i in df_predict['master_index_P100'].values]\n",
    "        x_col_ind = df_col_ref.columns.get_loc(metric_basis[0])\n",
    "        y_col_ind = df_col_ref.columns.get_loc(metric_basis[1])\n",
    "        x = scaled_data_[indices,x_col_ind][ipoint:ipoint+npoints]\n",
    "        y = scaled_data_[indices,y_col_ind][ipoint:ipoint+npoints]\n",
    "        ax.scatter(x, y, alpha=0.8, c='none', edgecolors=color, s=100, marker='s')\n",
    "\n",
    "        # Print V100 predictions (from measured P100 metrics)\n",
    "        if indices_to_predict: # Need to check that there are predictions to plot here...\n",
    "            x_col_ind = df_col_ref.columns.get_loc(metric_basis[0])\n",
    "            y_col_ind = df_col_ref.columns.get_loc(metric_basis[1]) \n",
    "            x = prediction[:,x_col_ind][ipoint:ipoint+npoints]\n",
    "            y = prediction[:,y_col_ind][ipoint:ipoint+npoints]\n",
    "            ax.scatter(x, y, alpha=0.8, c='none', edgecolors=color, s=400, marker='^')\n",
    "    \n",
    "        ax.set_xlabel(metric_basis[0]+' [Scaled]')\n",
    "        ax.set_ylabel(metric_basis[1]+' [Scaled]')\n",
    "\n",
    "plt.suptitle('NON-Memory-bound Applications on V100\\n(Squares == P100 Data, Triangles == Predicted V100 Data)')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting all backprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = (\"black\",) #, \"red\", \"green\", \"blue\")\n",
    "groups = ('backprop',) #, 'hybridsort', 'kmeans', 'srad')\n",
    "\n",
    "ipoint = 1#10  # Start with this case\n",
    "npoints = 200  # Plot this many cases (must be small to make visual sense)\n",
    "\n",
    "#df_plot = df_joined[df_joined['memory_bound_V100'] == 0].copy()\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(15,10))\n",
    "\n",
    "axs = [axes[0][0],axes[0][1],axes[1][0],axes[1][1]]\n",
    "\n",
    "for ix, ax in enumerate(axs):\n",
    "    ipoint += ix*npoints\n",
    "    for color, group in zip(colors, groups):\n",
    "        df_predict = df_plot[df_plot['application_name_V100'] == group].copy()\n",
    "        indices_to_predict = [int(i) for i in df_predict['master_index_P100'].values]\n",
    "        prediction = model.predict(scaled_data_[indices_to_predict])\n",
    "\n",
    "        # Print measured V100 metrics\n",
    "        indices = [int(i) for i in df_predict['master_index_V100'].values]\n",
    "        x_col_ind = df_col_ref.columns.get_loc(metric_basis[0])\n",
    "        y_col_ind = df_col_ref.columns.get_loc(metric_basis[1])\n",
    "        x = scaled_data_[indices,x_col_ind][ipoint:ipoint+npoints]\n",
    "        y = scaled_data_[indices,y_col_ind][ipoint:ipoint+npoints]\n",
    "        ax.scatter(x, y, alpha=0.8, c=color, edgecolors='none', s=20, marker='o', label=group)\n",
    "\n",
    "        # Print measured P100 metrics\n",
    "        indices = [int(i) for i in df_predict['master_index_P100'].values]\n",
    "        x_col_ind = df_col_ref.columns.get_loc(metric_basis[0])\n",
    "        y_col_ind = df_col_ref.columns.get_loc(metric_basis[1])\n",
    "        x = scaled_data_[indices,x_col_ind][ipoint:ipoint+npoints]\n",
    "        y = scaled_data_[indices,y_col_ind][ipoint:ipoint+npoints]\n",
    "        ax.scatter(x, y, alpha=0.8, c='none', edgecolors=color, s=100, marker='s')\n",
    "\n",
    "        # Print V100 predictions (from measured P100 metrics)\n",
    "        if indices_to_predict: # Need to check that there are predictions to plot here...\n",
    "            x_col_ind = df_col_ref.columns.get_loc(metric_basis[0])\n",
    "            y_col_ind = df_col_ref.columns.get_loc(metric_basis[1]) \n",
    "            x = prediction[:,x_col_ind][ipoint:ipoint+npoints]\n",
    "            y = prediction[:,y_col_ind][ipoint:ipoint+npoints]\n",
    "            ax.scatter(x, y, alpha=0.8, c='none', edgecolors=color, s=400, marker='^')\n",
    "    \n",
    "        ax.set_xlabel(metric_basis[0]+' [Scaled]')\n",
    "        ax.set_ylabel(metric_basis[1]+' [Scaled]')\n",
    "\n",
    "plt.suptitle('NON-Memory-bound Applications on V100\\n(Squares == P100 Data, Triangles == Predicted V100 Data)')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
